import os
import requests
import streamlit as st
import pandas as pd
import numpy as np
from urllib.parse import quote_plus
from bs4 import BeautifulSoup

# ===================== åŸºç¡€é…ç½® ===================== #

st.set_page_config(
    page_title="å¤–å–å¢é•¿æ½œåŠ›è¯Šæ–­å™¨",
    layout="wide"
)

st.title("ğŸ“ˆ é¤å…å¤–å–å¢é•¿æ½œåŠ›è¯Šæ–­å™¨")
st.caption("åŸºäº Google / Yelp / å¤–å–å¹³å°å…¬å¼€é¡µé¢ï¼Œè¯„ä¼°é¤å…ç²¾ç»†åŒ–è¿è¥åçš„å¤–å–å¢é•¿ç©ºé—´ã€‚")


# è¡Œä¸šç»éªŒï¼šç²¾ç»†åŒ–è¿è¥åï¼Œæ­£å¸¸å¯æå‡ 15%~60%
MIN_GROWTH = 0.15
MAX_GROWTH = 0.60


# ===================== Secret è¯»å–å·¥å…· ===================== #

def get_secret(name: str, default=None):
    """
    ä¼˜å…ˆä» st.secrets è¯»å–ï¼ˆStreamlit Cloud / æœ¬åœ° secrets.tomlï¼‰ï¼Œ
    è¯»å–ä¸åˆ°åˆ™ä»ç¯å¢ƒå˜é‡ä¸­æ‹¿ã€‚
    """
    try:
        return st.secrets[name]
    except Exception:
        return os.getenv(name, default)


YELP_API_KEY = get_secret("YELP_API_KEY")
GOOGLE_API_KEY = get_secret("GOOGLE_API_KEY")

if not YELP_API_KEY or not GOOGLE_API_KEY:
    st.warning("âš ï¸ æœªæ£€æµ‹åˆ° YELP_API_KEY æˆ– GOOGLE_API_KEYï¼Œè¯·å…ˆåœ¨ secrets.toml æˆ–ç¯å¢ƒå˜é‡ä¸­é…ç½®ã€‚")


# ===================== Google API ç›¸å…³ ===================== #

def google_geocode(address: str):
    """
    ä½¿ç”¨ Google Geocoding API å°†åœ°å€è½¬ä¸ºåæ ‡ã€‚
    """
    url = "https://maps.googleapis.com/maps/api/geocode/json"
    params = {
        "address": address,
        "key": GOOGLE_API_KEY
    }
    r = requests.get(url, params=params, timeout=15)
    data = r.json()
    if data.get("status") != "OK":
        return None, None
    loc = data["results"][0]["geometry"]["location"]
    return loc["lat"], loc["lng"]


def google_find_place(address: str):
    """
    ä½¿ç”¨ Places Find Place API æ‰¾åˆ° place_idã€‚
    """
    url = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json"
    params = {
        "key": GOOGLE_API_KEY,
        "input": address,
        "inputtype": "textquery",
        "fields": "place_id,name,geometry"
    }
    r = requests.get(url, params=params, timeout=15)
    data = r.json()
    candidates = data.get("candidates", [])
    if not candidates:
        return None
    return candidates[0]


def google_place_details(place_id: str):
    """
    è·å– Place è¯¦æƒ…ä¿¡æ¯ï¼ˆç›®å‰ä¸»è¦ç”¨äºè¯„åˆ†ã€è¯„è®ºæ•°é‡ï¼‰ã€‚
    Google API ä¸ç›´æ¥ç»™ç»“æ„åŒ–èœå•ï¼Œè¿™é‡Œåªå–åŸºæœ¬ä¿¡æ¯ã€‚
    """
    url = "https://maps.googleapis.com/maps/api/place/details/json"
    params = {
        "place_id": place_id,
        "key": GOOGLE_API_KEY,
        "fields": "name,rating,user_ratings_total,formatted_address"
    }
    r = requests.get(url, params=params, timeout=15)
    return r.json().get("result", {})


def fetch_google_dinein_menu(address: str) -> pd.DataFrame:
    """
    å ä½å‡½æ•°ï¼š
    Google å®˜æ–¹ API ç›®å‰ä¸ç›´æ¥æä¾›ç»“æ„åŒ–èœå•ã€‚
    å¦‚æœåç»­ä½ æƒ³è§£æ Google Maps ç½‘é¡µçš„èœå•ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ‰©å±• HTML è§£æé€»è¾‘ã€‚

    å½“å‰å…ˆè¿”å›ç©º DataFrameï¼Œåé¢è¯„åˆ†é€»è¾‘ä¼šè‡ªåŠ¨ç»™ä¸­æ€§è¯„åˆ†ã€‚
    """
    return pd.DataFrame(columns=["name", "price", "category", "channel"])


# ===================== Yelp API ç›¸å…³ ===================== #

def fetch_yelp_business_by_location(address: str):
    """
    é€šè¿‡åœ°å€ â†’ åæ ‡ â†’ Yelp æœç´¢é™„è¿‘è¯„åˆ†æœ€é«˜çš„ä¸€å®¶åº—è§†ä¸ºç›®æ ‡åº—ã€‚
    """
    if not YELP_API_KEY:
        return None

    lat, lng = google_geocode(address)
    if lat is None or lng is None:
        return None

    headers = {"Authorization": f"Bearer {YELP_API_KEY}"}
    url = "https://api.yelp.com/v3/businesses/search"
    params = {
        "latitude": lat,
        "longitude": lng,
        "limit": 1,
        "sort_by": "best_match"
    }
    r = requests.get(url, headers=headers, params=params, timeout=15)
    data = r.json()
    businesses = data.get("businesses", [])
    if not businesses:
        return None

    biz = businesses[0]
    return {
        "id": biz["id"],
        "name": biz["name"],
        "rating": biz.get("rating", None),
        "review_count": biz.get("review_count", 0),
        "price_level": biz.get("price", ""),
        "categories": [c["title"] for c in biz.get("categories", [])],
        "lat": biz["coordinates"]["latitude"],
        "lng": biz["coordinates"]["longitude"],
        "address": ", ".join(biz["location"].get("display_address", []))
    }


def fetch_yelp_competitors(lat: float, lng: float, term: str = "", radius_m: int = 1000) -> pd.DataFrame:
    """
    ä½¿ç”¨ Yelp æœç´¢ 1km å†…ç«å¯¹ã€‚
    """
    if not YELP_API_KEY:
        return pd.DataFrame()

    headers = {"Authorization": f"Bearer {YELP_API_KEY}"}
    url = "https://api.yelp.com/v3/businesses/search"
    params = {
        "latitude": lat,
        "longitude": lng,
        "radius": radius_m,
        "limit": 10,
        "sort_by": "rating",
    }
    if term:
        params["term"] = term

    r = requests.get(url, headers=headers, params=params, timeout=15)
    data = r.json()
    businesses = data.get("businesses", [])
    if not businesses:
        return pd.DataFrame()

    rows = []
    for b in businesses:
        rows.append({
            "name": b["name"],
            "rating": b.get("rating", None),
            "review_count": b.get("review_count", 0),
            "price_level": b.get("price", ""),
            "distance_m": b.get("distance", None),
            "categories": ", ".join([c["title"] for c in b.get("categories", [])]),
        })
    df = pd.DataFrame(rows)
    # è½¬ km
    if "distance_m" in df.columns:
        df["distance_km"] = df["distance_m"] / 1000.0
    return df


# ===================== å¤–å–å¹³å°ç½‘é¡µæœç´¢ & èœå•è§£æ ===================== #

def search_duckduckgo(query: str, max_results: int = 5):
    """
    ä½¿ç”¨ DuckDuckGo çš„ HTML ç»“æœé¡µé¢åšç®€å•æœç´¢ã€‚
    è¿™æ˜¯å…¬å¼€ Web æœç´¢ï¼Œä¸ä¾èµ–ä»»ä½•ç§æœ‰ APIã€‚
    """
    url = "https://duckduckgo.com/html/"
    params = {"q": query}
    r = requests.get(url, params=params, timeout=15, headers={"User-Agent": "Mozilla/5.0"})
    soup = BeautifulSoup(r.text, "html.parser")
    links = []
    for a in soup.select("a.result__a"):
        href = a.get("href")
        if href:
            links.append(href)
        if len(links) >= max_results:
            break
    return links


def find_delivery_links(restaurant_name: str, address: str):
    """
    é€šè¿‡æœç´¢æ‰¾åˆ° Doordash / UberEats çš„åº—é“ºé“¾æ¥ï¼ˆå°½åŠ›è€Œä¸ºï¼‰ã€‚
    """
    dd_link = None
    ue_link = None

    # ä»åœ°å€é‡ŒæŠ½ä¸€ç‚¹ç®€å•çš„ city / extra
    query_base = f'"{restaurant_name}" {address}'

    # æœç´¢ Doordash
    dd_results = search_duckduckgo(query_base + " site:doordash.com")
    for link in dd_results:
        if "doordash.com" in link:
            dd_link = link
            break

    # æœç´¢ UberEats
    ue_results = search_duckduckgo(query_base + " site:ubereats.com")
    for link in ue_results:
        if "ubereats.com" in link:
            ue_link = link
            break

    return dd_link, ue_link


def parse_doordash_menu(url: str) -> pd.DataFrame:
    """
    éå®˜æ–¹ Doordash èœå•è§£æï¼ˆåªè¯»å…¬å¼€ HTMLï¼Œå°½é‡ä»ä¸­æå–å“åå’Œä»·æ ¼ï¼‰ã€‚
    Doordash é¡µé¢ç»“æ„ç»å¸¸å˜åŠ¨ï¼Œæ­¤å¤„åªæ˜¯ä¸€ä¸ªâ€œèƒ½ç”¨å°±èµšåˆ°â€çš„å°è¯•ã€‚
    è§£æå¤±è´¥æ—¶è¿”å›ç©º DataFrameã€‚
    """
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        html = requests.get(url, headers=headers, timeout=20).text
        soup = BeautifulSoup(html, "html.parser")

        items = []
        # è¿™é‡Œçš„ CSS é€‰æ‹©å™¨åªæ˜¯ç¤ºä¾‹ï¼Œæœªæ¥å¯èƒ½éœ€è¦æ ¹æ®å®é™…é¡µé¢è°ƒæ•´
        for block in soup.find_all(["div", "article"]):
            name_tag = block.find("h3")
            if not name_tag:
                continue
            name = name_tag.get_text(strip=True)
            # æ‰¾ä»·æ ¼
            price = None
            for span in block.find_all("span"):
                text = span.get_text(strip=True)
                if text.startswith("$"):
                    try:
                        price = float(text.replace("$", "").strip())
                        break
                    except ValueError:
                        continue
            if name and price:
                items.append({
                    "name": name,
                    "price": price,
                    "category": "Unknown",
                    "channel": "doordash",
                    "tags": []
                })

        return pd.DataFrame(items) if items else pd.DataFrame(columns=["name", "price", "category", "channel", "tags"])
    except Exception:
        return pd.DataFrame(columns=["name", "price", "category", "channel", "tags"])


def parse_ubereats_menu(url: str) -> pd.DataFrame:
    """
    éå®˜æ–¹ UberEats èœå•è§£æï¼ˆåŒæ ·åªè¯»å…¬å¼€ HTMLï¼‰ã€‚
    ç»“æ„ä¹Ÿå¯èƒ½å˜åŠ¨ï¼Œå¤±è´¥æ—¶è¿”å›ç©ºè¡¨ã€‚
    """
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        html = requests.get(url, headers=headers, timeout=20).text
        soup = BeautifulSoup(html, "html.parser")

        items = []
        for block in soup.find_all(["div", "article"]):
            name_tag = block.find("h3")
            if not name_tag:
                continue
            name = name_tag.get_text(strip=True)
            price = None
            for span in block.find_all("span"):
                text = span.get_text(strip=True)
                if text.startswith("$"):
                    try:
                        price = float(text.replace("$", "").strip())
                        break
                    except ValueError:
                        continue
            if name and price:
                items.append({
                    "name": name,
                    "price": price,
                    "category": "Unknown",
                    "channel": "ubereats",
                    "tags": []
                })

        return pd.DataFrame(items) if items else pd.DataFrame(columns=["name", "price", "category", "channel", "tags"])
    except Exception:
        return pd.DataFrame(columns=["name", "price", "category", "channel", "tags"])


# ===================== åˆ†æé€»è¾‘ï¼ˆäº”å¤§ç»´åº¦ï¼‰ ===================== #

def compute_menu_structure_score(df_all: pd.DataFrame):
    """
    ç»´åº¦1ï¼šèœå•ç»“æ„å¥åº·åº¦ï¼ˆ0â€“100ï¼‰
    ç®€å•è§„åˆ™ï¼šèœå¤ªå°‘/å¤ªå¤šã€ç±»ç›®è¿‡å¤šã€ç¼ºå¥—é¤ â†’ æ‰£åˆ†ã€‚
    """
    tips = []

    if df_all is None or df_all.empty:
        return 55.0, ["æœªæˆåŠŸè·å–å¤–å–èœå•æ•°æ®ï¼Œæš‚ç”¨ä¸­æ€§åä¿å®ˆè¯„åˆ†ã€‚"]

    total_items = len(df_all)
    num_categories = df_all["category"].nunique() if "category" in df_all.columns else 1

    score = 100.0

    if total_items < 10:
        score -= 15
        tips.append("å¤–å–èœå•å•å“è¿‡å°‘ï¼Œç”¨æˆ·é€‰æ‹©æœ‰é™ï¼Œå»ºè®®è¡¥å…… 2â€“3 ä¸ªé«˜æ¯›åˆ© Star Itemã€‚")
    elif total_items > 60:
        score -= 25
        tips.append("å¤–å–èœå•å•å“è¶…è¿‡ 60 ä¸ªï¼Œå®¹æ˜“å¯¼è‡´é€‰æ‹©å›°éš¾ï¼Œå»ºè®®ç²¾ç®€å’Œåˆå¹¶éƒ¨åˆ†èœå“ã€‚")

    if num_categories > 8:
        score -= 15
        tips.append("èœå•ç±»åˆ«è¿‡å¤šï¼Œå»ºè®®å‹ç¼©åˆ° 5â€“7 ä¸ªä¸»ç±»ç›®ï¼Œçªå‡ºä¸»åŠ›å“ç±»ã€‚")

    has_combo = False
    for c in df_all.get("category", pd.Series()).dropna().astype(str):
        if "combo" in c.lower() or "å¥—é¤" in c:
            has_combo = True
            break
    if not has_combo:
        score -= 10
        tips.append("ç¼ºå°‘å¥—é¤/ç»„åˆèœå•ï¼Œå»ºè®®è®¾è®¡ 2â€“3 ä¸ªå®¢å•ä»·æ›´é«˜çš„å¥—é¤ç»„åˆï¼Œæå‡å®¢å•ä»·ã€‚")

    return max(score, 0), tips


def compute_pricing_score(df_dinein: pd.DataFrame, df_delivery: pd.DataFrame):
    """
    ç»´åº¦2ï¼šå®šä»·ä¸å®¢å•ä»·ç­–ç•¥ï¼ˆ0â€“100ï¼‰
    å ‚é£Ÿ vs å¤–å–çš„åŠ ä»·ç‡ã€‚
    æ²¡æœ‰å ‚é£Ÿæ•°æ®æ—¶ä½¿ç”¨ä¸­æ€§è¯„åˆ†ã€‚
    """
    tips = []

    if df_dinein is None or df_dinein.empty or df_delivery is None or df_delivery.empty:
        return 60.0, ["ç¼ºå°‘å®Œæ•´çš„å ‚é£Ÿ/å¤–å–ä»·æ ¼å¯¹æ¯”æ•°æ®ï¼Œæš‚ç”¨ä¸­æ€§è¯„åˆ†ã€‚"]

    merge = pd.merge(
        df_dinein[["name", "price"]],
        df_delivery[["name", "price"]],
        on="name",
        suffixes=("_dinein", "_delivery")
    )

    if merge.empty:
        return 60.0, ["å ‚é£Ÿä¸å¤–å–æœªæ‰¾åˆ°é‡å èœå“ï¼Œæ— æ³•ç²¾ç¡®æ¯”è¾ƒåŠ ä»·ç‡ã€‚"]

    merge["markup"] = (merge["price_delivery"] - merge["price_dinein"]) / merge["price_dinein"]
    avg_markup = merge["markup"].mean()

    score = 100.0
    if avg_markup < 0.10:
        score -= 15
        tips.append(f"å¤–å–æ•´ä½“åŠ ä»·ç‡çº¦ {avg_markup:.0%}ï¼Œåä½ï¼Œå»ºè®®é€‚å½“æé«˜åˆ° 15% å·¦å³ä»¥è¦†ç›–å¹³å°ä¸é…é€æˆæœ¬ã€‚")
    elif avg_markup > 0.35:
        score -= 20
        tips.append(f"å¤–å–æ•´ä½“åŠ ä»·ç‡çº¦ {avg_markup:.0%}ï¼Œåé«˜ï¼Œå¯èƒ½å½±å“è½¬åŒ–ç‡ï¼Œå»ºè®®æ§åˆ¶åœ¨ 15%â€“30% åŒºé—´ã€‚")
    else:
        tips.append(f"å¤–å–åŠ ä»·ç‡çº¦ {avg_markup:.0%}ï¼Œæ•´ä½“åˆç†ã€‚")

    return max(score, 0), tips


def compute_promotion_score(has_dd_link: bool, has_ue_link: bool):
    """
    ç»´åº¦3ï¼šæ´»åŠ¨ä½“ç³»ï¼ˆ0â€“100ï¼‰
    å½“å‰æ²¡æœ‰æ·±å…¥è§£ææ´»åŠ¨ï¼Œä»…ç”¨ç®€å•é€»è¾‘ï¼š
    - ä¸Šäº†ä¸¤ä¸ªå¹³å° â†’ è¯„åˆ†ç¨é«˜
    - ä¸€ä¸ªå¹³å° â†’ ä¸­æ€§
    - æ²¡ä¸Š â†’ åä½
    æœªæ¥å¯æ‰©å±•è§£æ BOGO / æ»¡å‡ ç­‰ä¿¡æ¯ã€‚
    """
    tips = []
    if not has_dd_link and not has_ue_link:
        score = 45.0
        tips.append("æš‚æœªå‘ç° Doordash / UberEats åº—é“ºé“¾æ¥ï¼Œå¤–å–æ¸ é“åŸºç¡€éœ€è¦å…ˆè¡¥é½ã€‚")
    elif has_dd_link and has_ue_link:
        score = 70.0
        tips.append("å·²è¦†ç›–ä¸»æµå¤–å–å¹³å°ï¼Œåç»­å¯é‡ç‚¹è®¾è®¡åˆ†å¹³å°å·®å¼‚åŒ–ä¼˜æƒ ä¸è€å®¢å¤è´­æ´»åŠ¨ã€‚")
    else:
        score = 60.0
        tips.append("å¤–å–å¹³å°éƒ¨åˆ†è¦†ç›–ï¼Œå»ºè®®åŒæ­¥æ‹“å±•è‡³ä¸»æµå¹³å°ï¼Œå¹¶åˆ¶å®šä¸€è‡´çš„ä»·æ ¼ä¸æ´»åŠ¨ç­–ç•¥ã€‚")

    tips.append("å½“å‰ç‰ˆæœ¬æœªè¯»å–å…·ä½“æ´»åŠ¨å†…å®¹ï¼Œå»ºè®®ä¸Šçº¿åæ­é…ï¼šé¦–å•å‡å…ã€åˆæ™šé«˜å³°æ»¡å‡ã€è€å®¢åˆ¸åŒ…ç­‰ç»„åˆç©æ³•ã€‚")
    return score, tips


def compute_competitor_score(df_comp: pd.DataFrame, restaurant_rating: float):
    """
    ç»´åº¦4ï¼šç«å¯¹å‹åŠ›æŒ‡æ•°ï¼ˆ0â€“100ï¼‰
    çœ‹è‡ªå·±è¯„åˆ† vs å‘¨è¾¹å‡å€¼ã€‚
    """
    tips = []

    if df_comp is None or df_comp.empty or restaurant_rating is None:
        return 60.0, ["ç«å¯¹æˆ–æœ¬åº—è¯„åˆ†æ•°æ®ä¸å®Œæ•´ï¼Œæš‚ç”¨ä¸­æ€§è¯„åˆ†ã€‚"]

    avg_comp_rating = df_comp["rating"].mean()
    diff = restaurant_rating - avg_comp_rating
    score = 60.0 + diff * 10
    score = max(min(score, 100.0), 0.0)

    if diff >= 0.2:
        tips.append(f"æœ¬åº— Yelp è¯„åˆ† {restaurant_rating:.1f} é«˜äºé™„è¿‘ç«å¯¹å‡å€¼ {avg_comp_rating:.1f}ï¼Œå£ç¢‘å…·å¤‡ä¼˜åŠ¿ï¼Œå¯ä»¥åœ¨å¤–å–è¯¦æƒ…é¡µæ›´çªå‡ºã€‚")
    elif diff <= -0.2:
        tips.append(f"æœ¬åº— Yelp è¯„åˆ† {restaurant_rating:.1f} ä½äºé™„è¿‘ç«å¯¹å‡å€¼ {avg_comp_rating:.1f}ï¼Œå»ºè®®é€šè¿‡æœåŠ¡ä½“éªŒã€åŒ…è£…ã€å¥½è¯„æ¿€åŠ±æ´»åŠ¨å¿«é€Ÿæ‹‰å‡è¯„åˆ†ã€‚")
    else:
        tips.append("æœ¬åº—è¯„åˆ†ä¸é™„è¿‘ç«å¯¹å¤§è‡´æŒå¹³ï¼Œå»ºè®®é€šè¿‡èœå“ç…§ç‰‡ã€æ–‡æ¡ˆä¸æ´»åŠ¨ç©æ³•åšå·®å¼‚åŒ–ã€‚")

    return score, tips


def compute_coverage_score():
    """
    ç»´åº¦5ï¼šé…é€è¦†ç›– & åœˆå±‚ï¼ˆ0â€“100ï¼‰
    å½“å‰ç‰ˆæœ¬æœªæ¥å…¥çœŸå®é…é€åŠå¾„ï¼Œç»™ä¸€ä¸ªä¸­æ€§åä¹è§‚è¯„åˆ†ã€‚
    æœªæ¥å¯ä»¥æ ¹æ®å¹³å° API æˆ–è‡ªå»ºæ•°æ®åšæ›´ç²¾ç»†çš„è¯„ä¼°ã€‚
    """
    score = 70.0
    tips = [
        "ä»åœ°ç†ä½ç½®å’Œå•†åœˆç»“æ„çš„é€šç”¨ç»éªŒçœ‹ï¼Œé…é€è¦†ç›–å…·å¤‡ä¸€å®šæ½œåŠ›ï¼Œ"
        "åç»­å¯ç»“åˆå®é™…å¹³å°é…é€åŠå¾„ä¸å­¦æ ¡/å†™å­—æ¥¼å¯†åº¦åšè¿›ä¸€æ­¥é‡åŒ–ã€‚"
    ]
    return score, tips


def compute_growth_rate(menu_score, price_score, promo_score, comp_score, coverage_score) -> float:
    """
    æ±‡æ€»äº”å¤§ç»´åº¦ï¼Œè®¡ç®—â€œæ½œåœ¨å¢é•¿ç‡â€ï¼ˆ0~1ï¼‰ï¼Œå¹¶é™åˆ¶åœ¨ MIN_GROWTH ~ MAX_GROWTH åŒºé—´ã€‚
    """
    weighted = (
        0.20 * menu_score +
        0.15 * price_score +
        0.25 * promo_score +
        0.15 * comp_score +
        0.25 * coverage_score
    ) / 100.0
    growth_rate = MIN_GROWTH + (MAX_GROWTH - MIN_GROWTH) * weighted
    return growth_rate


# ===================== æ ¸å¿ƒåˆ†æç®¡çº¿ ===================== #

def analyze_restaurant(address: str, avg_orders: float, avg_ticket: float):
    """
    æ ¸å¿ƒæµç¨‹ï¼š
    1. Yelp æ‰¾åˆ°ç›®æ ‡åº— & ç«å¯¹
    2. Google è·å– Place ä¿¡æ¯
    3. æœç´¢ Doordash / UberEats é“¾æ¥å¹¶å°è¯•è§£æèœå•
    4. è®¡ç®—äº”å¤§ç»´åº¦è¯„åˆ†
    5. é¢„ä¼°å¤–å–è¥ä¸šé¢æå‡ç©ºé—´
    """
    # 1. Yelp åŸºç¡€ä¿¡æ¯
    yelp_info = fetch_yelp_business_by_location(address)
    if not yelp_info:
        raise RuntimeError("æ ¹æ®åœ°å€æœªåœ¨ Yelp æ‰¾åˆ°åŒ¹é…é¤å…ï¼Œè¯·æ£€æŸ¥åœ°å€æ˜¯å¦æ­£ç¡®ã€‚")

    # 2. Google Place ä¿¡æ¯
    place_info = None
    place = google_find_place(address)
    if place and place.get("place_id"):
        place_info = google_place_details(place["place_id"])

    # 3. ç«å¯¹ï¼ˆæŒ‰ Yelpï¼‰
    comp_df = fetch_yelp_competitors(yelp_info["lat"], yelp_info["lng"])

    # 4. èœå•æ•°æ®
    dinein_df = fetch_google_dinein_menu(address)  # å½“å‰ä¸ºç©ºå ä½
    # æœç´¢å¤–å–å¹³å°é“¾æ¥
    dd_link, ue_link = find_delivery_links(yelp_info["name"], yelp_info["address"])
    dd_df = parse_doordash_menu(dd_link) if dd_link else pd.DataFrame(columns=["name", "price", "category", "channel", "tags"])
    ue_df = parse_ubereats_menu(ue_link) if ue_link else pd.DataFrame(columns=["name", "price", "category", "channel", "tags"])

    all_df = pd.concat([dinein_df, dd_df, ue_df], ignore_index=True) if not (dd_df.empty and ue_df.empty) else pd.DataFrame()

    # 5. è¯„åˆ†ä¸å»ºè®®
    menu_score, menu_tips = compute_menu_structure_score(all_df)
    price_score, price_tips = compute_pricing_score(dinein_df, dd_df if not dd_df.empty else ue_df)
    promo_score, promo_tips = compute_promotion_score(has_dd_link=dd_link is not None, has_ue_link=ue_link is not None)
    comp_score, comp_tips = compute_competitor_score(comp_df, yelp_info.get("rating", None))
    coverage_score, coverage_tips = compute_coverage_score()

    growth_rate = compute_growth_rate(menu_score, price_score, promo_score, comp_score, coverage_score)

    current_daily_revenue = avg_orders * avg_ticket
    potential_daily_revenue = current_daily_revenue * (1 + growth_rate)
    revenue_uplift_daily = potential_daily_revenue - current_daily_revenue
    revenue_uplift_monthly = revenue_uplift_daily * 30

    result = {
        "yelp_info": yelp_info,
        "place_info": place_info,
        "competitors": comp_df,
        "delivery_links": {
            "doordash": dd_link,
            "ubereats": ue_link
        },
        "menus": {
            "dinein": dinein_df,
            "doordash": dd_df,
            "ubereats": ue_df,
            "all": all_df
        },
        "scores": {
            "èœå•ç»“æ„": menu_score,
            "å®šä»·ä¸å®¢å•ä»·": price_score,
            "æ´»åŠ¨ä½“ç³»": promo_score,
            "ç«å¯¹å‹åŠ›": comp_score,
            "è¦†ç›–ä¸åœˆå±‚": coverage_score,
        },
        "tips": {
            "èœå•ç»“æ„": menu_tips,
            "å®šä»·ä¸å®¢å•ä»·": price_tips,
            "æ´»åŠ¨ä½“ç³»": promo_tips,
            "ç«å¯¹å‹åŠ›": comp_tips,
            "è¦†ç›–ä¸åœˆå±‚": coverage_tips,
        },
        "growth_rate": growth_rate,
        "current_daily_revenue": current_daily_revenue,
        "potential_daily_revenue": potential_daily_revenue,
        "revenue_uplift_daily": revenue_uplift_daily,
        "revenue_uplift_monthly": revenue_uplift_monthly,
    }

    return result


# ===================== Streamlit UI ===================== #

with st.form("input_form"):
    st.subheader("ğŸ“ è¯·è¾“å…¥é¤å…åŸºç¡€æ•°æ®")

    address = st.text_input("é¤å…åœ°å€ï¼ˆç”¨äºåŒ¹é… Yelp / Google / å¤–å–å¹³å°ï¼‰", "")
    col1, col2 = st.columns(2)
    with col1:
        avg_orders = st.number_input("å½“å‰æ—¥å‡å¤–å–å•é‡ï¼ˆå•ï¼‰", min_value=0.0, value=30.0, step=1.0)
    with col2:
        avg_ticket = st.number_input("å½“å‰å¤–å–å®¢å•ä»·ï¼ˆç¾å…ƒï¼‰", min_value=0.0, value=25.0, step=1.0)

    submitted = st.form_submit_button("ğŸš€ å¼€å§‹è¯Šæ–­")

if submitted:
    if not address.strip():
        st.error("è¯·è¾“å…¥é¤å…åœ°å€ã€‚")
    else:
        try:
            with st.spinner("æ­£åœ¨åŸºäº Yelp / Google / å¤–å–å¹³å°æ•°æ®è¿›è¡Œè¯Šæ–­..."):
                result = analyze_restaurant(address, avg_orders, avg_ticket)

            # é¡¶éƒ¨ KPI æ¦‚è§ˆ
            st.subheader("ğŸ“Š è¯Šæ–­ç»“æœæ€»è§ˆ")

            col_a, col_b, col_c = st.columns(3)
            with col_a:
                st.metric(
                    "å½“å‰æ—¥å¤–å–è¥ä¸šé¢ï¼ˆä¼°ç®—ï¼‰",
                    f"${result['current_daily_revenue']:.0f}"
                )
            with col_b:
                st.metric(
                    "ä¼˜åŒ–åæ—¥å¤–å–è¥ä¸šé¢ï¼ˆé¢„æµ‹ï¼‰",
                    f"${result['potential_daily_revenue']:.0f}"
                )
            with col_c:
                st.metric(
                    "æœˆåº¦å¯æå‡å¤–å–è¥ä¸šé¢ï¼ˆé¢„æµ‹ï¼‰",
                    f"+${result['revenue_uplift_monthly']:.0f}"
                )

            st.write(
                f"ç»¼åˆèœå•ç»“æ„ã€å®šä»·ç­–ç•¥ã€æ´»åŠ¨ä½“ç³»ã€ç«å¯¹å‹åŠ›ä¸é…é€è¦†ç›–æƒ…å†µï¼Œ"
                f"ç³»ç»Ÿé¢„ä¼°é€šè¿‡ç²¾ç»†åŒ–è¿è¥ï¼Œå¯å¸¦æ¥çº¦ **{result['growth_rate']*100:.1f}%** çš„å¤–å–è¥ä¸šé¢å¢é•¿ç©ºé—´ã€‚"
            )

            # äº”å¤§ç»´åº¦è¯„åˆ†
            st.subheader("ğŸ§¬ äº”å¤§ç»´åº¦è¯Šæ–­è¯„åˆ†")
            score_df = pd.DataFrame(
                {
                    "ç»´åº¦": list(result["scores"].keys()),
                    "å¾—åˆ†": list(result["scores"].values()),
                }
            )
            st.bar_chart(score_df.set_index("ç»´åº¦"))

            # ç»´åº¦å»ºè®®
            st.subheader("ğŸ©º åˆ†ç»´åº¦è¿è¥å»ºè®®")
            for dim, tips in result["tips"].items():
                with st.expander(f"{dim} Â· è¯Šæ–­å»ºè®®"):
                    for t in tips:
                        st.markdown(f"- {t}")

            # Yelp / Google åŸºæœ¬ä¿¡æ¯
            st.subheader("ğŸª åº—é“ºåŸºç¡€ä¿¡æ¯ï¼ˆæ¥è‡ª Yelp / Googleï¼‰")
            col_y1, col_y2 = st.columns(2)
            with col_y1:
                st.markdown("**Yelp ä¿¡æ¯**")
                yi = result["yelp_info"]
                st.write(f"åº—åï¼š{yi['name']}")
                st.write(f"åœ°å€ï¼š{yi['address']}")
                st.write(f"è¯„åˆ†ï¼š{yi.get('rating', 'N/A')} â­ï¸ï¼ˆ{yi.get('review_count', 0)} æ¡è¯„è®ºï¼‰")
                st.write(f"ä»·æ ¼ç­‰çº§ï¼š{yi.get('price_level', 'N/A')}")
                st.write(f"å“ç±»ï¼š{', '.join(yi.get('categories', []))}")

            with col_y2:
                st.markdown("**Google Place ä¿¡æ¯ï¼ˆè‹¥åŒ¹é…æˆåŠŸï¼‰**")
                gi = result.get("place_info")
                if gi:
                    st.write(f"åº—åï¼š{gi.get('name', 'N/A')}")
                    st.write(f"åœ°å€ï¼š{gi.get('formatted_address', 'N/A')}")
                    st.write(f"è¯„åˆ†ï¼š{gi.get('rating', 'N/A')} â­ï¸ï¼ˆ{gi.get('user_ratings_total', 0)} æ¡è¯„è®ºï¼‰")
                else:
                    st.write("æœªä» Google Places æ‰¾åˆ°æ›´å¤šè¯¦æƒ…ã€‚")

            # å¤–å–å¹³å°é“¾æ¥
            st.subheader("ğŸšš å¤–å–å¹³å°è¦†ç›–æƒ…å†µ")
            dl = result["delivery_links"]
            if dl["doordash"]:
                st.markdown(f"- âœ… Doordashï¼š[{dl['doordash']}]({dl['doordash']})")
            else:
                st.markdown("- âŒ æœªå‘ç° Doordash åº—é“ºé“¾æ¥")

            if dl["ubereats"]:
                st.markdown(f"- âœ… UberEatsï¼š[{dl['ubereats']}]({dl['ubereats']})")
            else:
                st.markdown("- âŒ æœªå‘ç° UberEats åº—é“ºé“¾æ¥")

            # èœå•è¡¨
            st.subheader("ğŸ“‘ èœå•æ•°æ®ï¼ˆè‹¥è§£ææˆåŠŸï¼‰")
            tab1, tab2, tab3, tab4 = st.tabs(["å ‚é£Ÿï¼ˆGoogleï¼‰", "Doordash èœå•", "UberEats èœå•", "æ•´åˆè§†å›¾"])
            with tab1:
                if result["menus"]["dinein"].empty:
                    st.write("å½“å‰ç‰ˆæœ¬æœªä» Google è§£æç»“æ„åŒ–å ‚é£Ÿèœå•ã€‚")
                else:
                    st.dataframe(result["menus"]["dinein"])
            with tab2:
                if result["menus"]["doordash"].empty:
                    st.write("æœªè§£æåˆ° Doordash èœå•ç»“æ„ã€‚")
                else:
                    st.dataframe(result["menus"]["doordash"])
            with tab3:
                if result["menus"]["ubereats"].empty:
                    st.write("æœªè§£æåˆ° UberEats èœå•ç»“æ„ã€‚")
                else:
                    st.dataframe(result["menus"]["ubereats"])
            with tab4:
                if result["menus"]["all"].empty:
                    st.write("æš‚æ— å¯ç”¨èœå•æ•°æ®ã€‚")
                else:
                    st.dataframe(result["menus"]["all"])

            # ç«å¯¹
            st.subheader("ğŸ é™„è¿‘ç«å¯¹æ¦‚è§ˆï¼ˆæ¥è‡ª Yelpï¼‰")
            if result["competitors"].empty:
                st.write("æœªè·å–åˆ°ç«å¯¹æ•°æ®ã€‚")
            else:
                st.dataframe(result["competitors"])

            st.info(
                "å½“å‰ç‰ˆæœ¬å·²æ¥å…¥çœŸå® Yelp / Google APIï¼Œå¤–å–å¹³å°èœå•è§£æåŸºäºå…¬å¼€ç½‘é¡µç»“æ„ï¼Œ"
                "è‹¥å¹³å°æ”¹ç‰ˆæˆ–ä¸ªåˆ«é¡µé¢ç»“æ„ç‰¹æ®Šï¼Œå¯èƒ½å‡ºç°è§£æä¸åˆ°èœå•çš„æƒ…å†µï¼Œè¯„åˆ†ä¼šè‡ªåŠ¨å›é€€ä¸ºä¸­æ€§ã€‚"
            )

        except Exception as e:
            st.error(f"è¯Šæ–­è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{e}")

else:
    st.markdown(
        """
        ### ä½¿ç”¨è¯´æ˜
        1. å¡«å†™é¤å…åœ°å€ + å½“å‰æ—¥å‡å¤–å–å•é‡ + å¤–å–å®¢å•ä»·  
        2. ç³»ç»Ÿä¼šé€šè¿‡ **Yelp / Google API** å®šä½åº—é“ºä¸ç«å¯¹ï¼Œé€šè¿‡å…¬å¼€ç½‘é¡µæœç´¢å°è¯•æ‰¾åˆ° Doordash / UberEats åº—é“ºé¡µé¢ï¼›  
        3. åœ¨èƒ½è§£æåˆ°çš„å‰æä¸‹ï¼Œå¯¹èœå•ç»“æ„ã€ä»·æ ¼ç­–ç•¥ã€å¤–å–å¹³å°è¦†ç›–ã€ç«å¯¹æƒ…å†µåšé‡åŒ–è¯„åˆ†ï¼›  
        4. è¾“å‡ºä¸€ä»½ã€Œå¤–å–è¥ä¸šé¢å¯æå‡ç©ºé—´ã€çš„é¢„æµ‹ç»“æœ + åˆ†ç»´åº¦è¿è¥å»ºè®®ï¼Œå¯ç›´æ¥ç”¨äºå’Œè€æ¿/å®¢æˆ·æ²Ÿé€šã€‚  
        """
    )
