import os
import json
import datetime
from urllib.parse import urlparse, parse_qs, unquote

import numpy as np
import pandas as pd
import requests
import streamlit as st
from bs4 import BeautifulSoup

# ====== å°è¯•å¯¼å…¥ OpenAI SDKï¼ˆæ²¡è£…ä¹Ÿä¸è¦è®© app å´©ï¼‰ ====== #
try:
    from openai import OpenAI
except ModuleNotFoundError:
    OpenAI = None

# ===================== åŸºç¡€é…ç½® ===================== #

st.set_page_config(
    page_title="å¤–å–å¢é•¿æ½œåŠ›è¯Šæ–­å™¨",
    layout="wide"
)

st.title("ğŸ“ˆ é¤å…å¤–å–å¢é•¿æ½œåŠ›è¯Šæ–­å™¨")
st.caption("åŸºäº Google / Yelp / å¤–å–å¹³å°å…¬å¼€é¡µé¢ + å¤§æ¨¡å‹åˆ†æï¼Œè¯„ä¼°é¤å…ç²¾ç»†åŒ–è¿è¥åçš„å¤–å–å¢é•¿ç©ºé—´ã€‚")

# è¡Œä¸šç»éªŒï¼šç²¾ç»†åŒ–è¿è¥åï¼Œæ­£å¸¸å¯æå‡ 15%~60%
MIN_GROWTH = 0.15
MAX_GROWTH = 0.60


# ===================== Secret è¯»å–å·¥å…· ===================== #

def get_secret(name: str, default=None):
    """ä¼˜å…ˆä» st.secrets è¯»å–ï¼Œè¯»å–ä¸åˆ°åˆ™ä»ç¯å¢ƒå˜é‡ä¸­æ‹¿ã€‚"""
    try:
        return st.secrets[name]
    except Exception:
        return os.getenv(name, default)


YELP_API_KEY = get_secret("YELP_API_KEY")
GOOGLE_API_KEY = get_secret("GOOGLE_API_KEY")
OPENAI_API_KEY = get_secret("OPENAI_API_KEY")

if not YELP_API_KEY or not GOOGLE_API_KEY:
    st.warning("âš ï¸ æœªæ£€æµ‹åˆ° YELP_API_KEY æˆ– GOOGLE_API_KEYï¼Œè¯·å…ˆåœ¨ secrets.toml æˆ–ç¯å¢ƒå˜é‡ä¸­é…ç½®ã€‚")

if not OPENAI_API_KEY or OpenAI is None:
    st.info("ğŸ’¡ æœªé…ç½® OPENAI_API_KEY æˆ–æœªå®‰è£… openai SDKï¼Œå°†è·³è¿‡ AI æ·±åº¦åˆ†æï¼Œåªä½¿ç”¨è§„åˆ™å¼•æ“ã€‚")

# OpenAI clientï¼ˆåªæœ‰ key + SDK éƒ½é½æ‰åˆå§‹åŒ–ï¼‰
client = OpenAI(api_key=OPENAI_API_KEY) if (OPENAI_API_KEY and OpenAI is not None) else None


# ===================== Google / Yelp / DuckDuckGo ç­‰è°ƒç”¨åŠ ç¼“å­˜ ===================== #

@st.cache_data(show_spinner=False)
def google_geocode(address: str):
    """ä½¿ç”¨ Google Geocoding API å°†åœ°å€è½¬ä¸ºåæ ‡ã€‚"""
    url = "https://maps.googleapis.com/maps/api/geocode/json"
    params = {"address": address, "key": GOOGLE_API_KEY}
    r = requests.get(url, params=params, timeout=15)
    data = r.json()
    if data.get("status") != "OK":
        return None, None
    loc = data["results"][0]["geometry"]["location"]
    return loc["lat"], loc["lng"]


@st.cache_data(show_spinner=False)
def google_find_place_cached(input_text: str):
    """ç¼“å­˜ç‰ˆ Find Place åŸºç¡€è°ƒç”¨ã€‚"""
    url = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json"
    params = {
        "key": GOOGLE_API_KEY,
        "input": input_text,
        "inputtype": "textquery",
        "fields": "place_id,name,geometry,types,rating,user_ratings_total,formatted_address"
    }
    r = requests.get(url, params=params, timeout=15)
    return r.json()


def google_find_place(input_text: str, prefer_restaurant: bool = False, ref_name: str = None):
    """
    ä½¿ç”¨ Places Find Place API æ‰¾åˆ° place ä¿¡æ¯ã€‚
    - prefer_restaurant=True æ—¶ï¼Œä¼šä¼˜å…ˆé€‰é¤é¥®ç±»å‹ + æœ‰è¯„åˆ†çš„å€™é€‰
    - ref_name ç”¨äºç®€å•åç§°ç›¸ä¼¼åº¦åŠ æƒ
    """
    data = google_find_place_cached(input_text)
    candidates = data.get("candidates", []) if isinstance(data, dict) else []
    if not candidates:
        return None

    # ä¸å¼ºåˆ¶é¤é¥®å°±ç›´æ¥ç”¨ç¬¬ä¸€ä¸ª
    if not prefer_restaurant:
        return candidates[0]

    primary_food_types = {"restaurant", "food", "meal_takeaway", "meal_delivery"}
    secondary_food_types = {"cafe", "bar", "bakery"}

    scored = []
    ref_name_lower = ref_name.lower() if ref_name else None

    for c in candidates:
        score = 0
        types = c.get("types", []) or []

        if any(t in primary_food_types for t in types):
            score += 3
        elif any(t in secondary_food_types for t in types):
            score += 1

        if c.get("user_ratings_total", 0) > 0:
            score += 1

        if ref_name_lower:
            name = c.get("name", "") or ""
            if ref_name_lower in name.lower():
                score += 3

        scored.append((score, c))

    best_score, best_cand = max(scored, key=lambda x: x[0])
    if best_score == 0:
        return candidates[0]
    return best_cand


@st.cache_data(show_spinner=False)
def google_place_details(place_id: str):
    """è·å– Place è¯¦æƒ…ä¿¡æ¯ï¼ˆä¸»è¦ç”¨äºè¯„åˆ†ã€è¯„è®ºæ•°é‡ï¼‰ã€‚"""
    url = "https://maps.googleapis.com/maps/api/place/details/json"
    params = {
        "place_id": place_id,
        "key": GOOGLE_API_KEY,
        "fields": "name,rating,user_ratings_total,formatted_address,price_level"
    }
    r = requests.get(url, params=params, timeout=15)
    return r.json().get("result", {})


def fetch_google_dinein_menu(address: str) -> pd.DataFrame:
    """
    å ä½å‡½æ•°ï¼š
    Google å®˜æ–¹ API ç›®å‰ä¸ç›´æ¥æä¾›ç»“æ„åŒ–èœå•ã€‚
    å¦‚éœ€è§£æ Google Maps ç½‘é¡µèœå•ï¼Œå¯åœ¨è¿™é‡Œæ‰©å±• HTML è§£æã€‚
    """
    return pd.DataFrame(columns=["name", "price", "category", "channel"])


@st.cache_data(show_spinner=False)
def fetch_yelp_candidates_by_address(address: str, limit: int = 5):
    """
    ç¨³å®šçš„åœ°å€ â†’ Yelp åŒ¹é…ã€‚
    """
    if not YELP_API_KEY:
        return []

    headers = {"Authorization": f"Bearer {YELP_API_KEY}"}
    url = "https://api.yelp.com/v3/businesses/search"

    lat, lng = google_geocode(address)

    if lat is None or lng is None:
        search_params = {"location": address, "limit": limit, "sort_by": "distance"}
    else:
        search_params = {
            "latitude": lat,
            "longitude": lng,
            "radius": 150,   # å•ä½ï¼šç±³
            "limit": limit,
            "sort_by": "distance"
        }

    r = requests.get(url, headers=headers, params=search_params, timeout=15)
    data = r.json()
    businesses = data.get("businesses", [])
    candidates = []

    if not businesses:
        return []

    for b in businesses:
        display_address = ", ".join(b["location"].get("display_address", []))
        cats = [c["title"] for c in b.get("categories", [])]

        candidates.append(
            {
                "id": b["id"],
                "name": b["name"],
                "rating": b.get("rating", None),
                "review_count": b.get("review_count", 0),
                "price_level": b.get("price", ""),
                "categories": cats,
                "categories_str": ", ".join(cats),
                "lat": b["coordinates"]["latitude"],
                "lng": b["coordinates"]["longitude"],
                "address": display_address,
                "source": "yelp",
            }
        )

    return candidates


@st.cache_data(show_spinner=False)
def fetch_yelp_competitors(lat: float, lng: float, term: str = "", radius_m: int = 600) -> pd.DataFrame:
    """ä½¿ç”¨ Yelp æœç´¢é™„è¿‘ç«å¯¹ï¼Œé»˜è®¤åŠå¾„ 600mã€‚"""
    if not YELP_API_KEY:
        return pd.DataFrame()

    headers = {"Authorization": f"Bearer {YELP_API_KEY}"}
    url = "https://api.yelp.com/v3/businesses/search"
    params = {
        "latitude": lat,
        "longitude": lng,
        "radius": radius_m,
        "limit": 10,
        "sort_by": "rating",
    }
    if term:
        params["term"] = term

    r = requests.get(url, headers=headers, params=params, timeout=15)
    data = r.json()
    businesses = data.get("businesses", [])
    if not businesses:
        return pd.DataFrame()

    rows = []
    for b in businesses:
        rows.append({
            "name": b["name"],
            "rating": b.get("rating", None),
            "review_count": b.get("review_count", 0),
            "price_level": b.get("price", ""),
            "distance_m": b.get("distance", None),
            "categories": ", ".join([c["title"] for c in b.get("categories", [])]),
        })
    df = pd.DataFrame(rows)
    if "distance_m" in df.columns:
        df["distance_km"] = df["distance_m"] / 1000.0
    return df


@st.cache_data(show_spinner=False)
def search_duckduckgo(query: str, max_results: int = 3):
    """
    ä½¿ç”¨ DuckDuckGo çš„ HTML ç»“æœé¡µé¢åšç®€å•æœç´¢ã€‚
    æ³¨æ„å¾ˆå¤šé“¾æ¥æ˜¯ /l/?uddg=ï¼Œéœ€è¦è§£ç æˆçœŸå® URLã€‚
    """
    url = "https://duckduckgo.com/html/"
    params = {"q": query}
    r = requests.get(
        url,
        params=params,
        timeout=15,
        headers={"User-Agent": "Mozilla/5.0"}
    )
    soup = BeautifulSoup(r.text, "html.parser")
    links = []
    for a in soup.select("a.result__a"):
        href = a.get("href")
        if not href:
            continue

        real_url = href
        if href.startswith("/l/"):
            parsed = urlparse(href)
            qs = parse_qs(parsed.query)
            if "uddg" in qs and qs["uddg"]:
                real_url = unquote(qs["uddg"][0])

        links.append(real_url)
        if len(links) >= max_results:
            break
    return links


def find_delivery_links(restaurant_name: str, address: str):
    """é€šè¿‡æœç´¢æ‰¾åˆ° Doordash / UberEats çš„åº—é“ºé“¾æ¥ï¼ˆå°½åŠ›è€Œä¸ºï¼‰ã€‚"""
    dd_link, ue_link = None, None
    query_base = f'"{restaurant_name}" {address}'

    dd_results = search_duckduckgo(query_base + " site:doordash.com")
    for link in dd_results:
        if "doordash.com" in link:
            dd_link = link
            break

    ue_results = search_duckduckgo(query_base + " site:ubereats.com")
    for link in ue_results:
        if "ubereats.com" in link:
            ue_link = link
            break

    return dd_link, ue_link


@st.cache_data(show_spinner=False)
def parse_doordash_menu(url: str) -> pd.DataFrame:
    """éå®˜æ–¹ Doordash èœå•è§£æï¼Œåªè¯»å…¬å¼€ HTMLã€‚"""
    if not url:
        return pd.DataFrame(columns=["name", "price", "category", "channel", "tags"])
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        html = requests.get(url, headers=headers, timeout=10).text
        soup = BeautifulSoup(html, "html.parser")

        items = []
        for block in soup.find_all(["div", "article"]):
            name_tag = block.find("h3")
            if not name_tag:
                continue
            name = name_tag.get_text(strip=True)
            price = None
            for span in block.find_all("span"):
                text = span.get_text(strip=True)
                if text.startswith("$"):
                    try:
                        price = float(text.replace("$", "").strip())
                        break
                    except ValueError:
                        continue
            if name and price is not None:
                items.append({
                    "name": name,
                    "price": price,
                    "category": "Unknown",
                    "channel": "doordash",
                    "tags": []
                })

        return pd.DataFrame(items) if items else pd.DataFrame(
            columns=["name", "price", "category", "channel", "tags"])
    except Exception:
        return pd.DataFrame(columns=["name", "price", "category", "channel", "tags"])


@st.cache_data(show_spinner=False)
def parse_ubereats_menu(url: str) -> pd.DataFrame:
    """éå®˜æ–¹ UberEats èœå•è§£æï¼Œåªè¯»å…¬å¼€ HTMLã€‚"""
    if not url:
        return pd.DataFrame(columns=["name", "price", "category", "channel", "tags"])
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        html = requests.get(url, headers=headers, timeout=10).text
        soup = BeautifulSoup(html, "html.parser")

        items = []
        for block in soup.find_all(["div", "article"]):
            name_tag = block.find("h3")
            if not name_tag:
                continue
            name = name_tag.get_text(strip=True)
            price = None
            for span in block.find_all("span"):
                text = span.get_text(strip=True)
                if text.startswith("$"):
                    try:
                        price = float(text.replace("$", "").strip())
                        break
                    except ValueError:
                        continue
            if name and price is not None:
                items.append({
                    "name": name,
                    "price": price,
                    "category": "Unknown",
                    "channel": "ubereats",
                    "tags": []
                })

        return pd.DataFrame(items) if items else pd.DataFrame(
            columns=["name", "price", "category", "channel", "tags"])
    except Exception:
        return pd.DataFrame(columns=["name", "price", "category", "channel", "tags"])


# ===================== è§„åˆ™è¯„åˆ†ï¼ˆå…­å¤§ç»´åº¦ï¼‰ ===================== #

def compute_menu_structure_score(df_all: pd.DataFrame):
    tips = []
    if df_all is None or df_all.empty:
        return 55.0, ["æœªæˆåŠŸè·å–å¤–å–èœå•æ•°æ®ï¼Œæš‚ç”¨ä¸­æ€§åä¿å®ˆè¯„åˆ†ã€‚"]

    total_items = len(df_all)
    num_categories = df_all["category"].nunique() if "category" in df_all.columns else 1

    score = 100.0

    if total_items < 10:
        score -= 15
        tips.append(f"å½“å‰å¤–å–èœå•å…± **{total_items}** ä¸ªèœå“ï¼Œåå°‘ï¼Œç”¨æˆ·é€‰æ‹©æœ‰é™ï¼Œå»ºè®®è¡¥å…… 2â€“3 ä¸ªé«˜æ¯›åˆ© Star Itemã€‚")
    elif total_items > 60:
        score -= 25
        tips.append(f"å½“å‰å¤–å–èœå•å…± **{total_items}** ä¸ªèœå“ï¼Œ>60 ä¸ªï¼Œå®¹æ˜“å¯¼è‡´é€‰æ‹©å›°éš¾ï¼Œå»ºè®®ç²¾ç®€å’Œåˆå¹¶éƒ¨åˆ†èœå“ã€‚")
    else:
        tips.append(f"å½“å‰å¤–å–èœå•å•å“æ•°é‡çº¦ **{total_items}** ä¸ªï¼Œå¤„åœ¨å¯æ§èŒƒå›´å†…ã€‚")

    if num_categories > 8:
        score -= 15
        tips.append(f"èœå•ç±»åˆ«æ•°é‡çº¦ **{num_categories}** ä¸ªï¼Œåå¤šï¼Œå»ºè®®å‹ç¼©åˆ° 5â€“7 ä¸ªä¸»ç±»ç›®ï¼Œçªå‡ºä¸»åŠ›å“ç±»ã€‚")
    else:
        tips.append(f"èœå•ç±»åˆ«æ•°é‡çº¦ **{num_categories}** ä¸ªã€‚")

    has_combo = False
    for c in df_all.get("category", pd.Series()).dropna().astype(str):
        if "combo" in c.lower() or "å¥—é¤" in c:
            has_combo = True
            break
    if not has_combo:
        score -= 10
        tips.append("ç¼ºå°‘å¥—é¤/ç»„åˆèœå•ï¼Œå»ºè®®è®¾è®¡ 2â€“3 ä¸ªå®¢å•ä»·æ›´é«˜çš„å¥—é¤ç»„åˆï¼Œæå‡å®¢å•ä»·ã€‚")
    else:
        tips.append("å·²æ£€æµ‹åˆ°å¥—é¤/ç»„åˆç±»ç›®ï¼Œå¯åœ¨æ­¤åŸºç¡€ä¸Šç»§ç»­ä¼˜åŒ–å®¢å•ä»·ç»“æ„ã€‚")

    return max(score, 0), tips


def compute_pricing_score(df_dinein: pd.DataFrame, df_delivery: pd.DataFrame):
    tips = []
    if df_dinein is None or df_dinein.empty or df_delivery is None or df_delivery.empty:
        return 60.0, ["ç¼ºå°‘å®Œæ•´çš„å ‚é£Ÿ/å¤–å–ä»·æ ¼å¯¹æ¯”æ•°æ®ï¼Œæš‚ç”¨ä¸­æ€§è¯„åˆ†ã€‚"]

    merge = pd.merge(
        df_dinein[["name", "price"]],
        df_delivery[["name", "price"]],
        on="name",
        suffixes=("_dinein", "_delivery")
    )
    if merge.empty:
        return 60.0, ["å ‚é£Ÿä¸å¤–å–æœªæ‰¾åˆ°é‡å èœå“ï¼Œæ— æ³•ç²¾ç¡®æ¯”è¾ƒåŠ ä»·ç‡ã€‚"]

    merge["markup"] = (merge["price_delivery"] - merge["price_dinein"]) / merge["price_dinein"]
    avg_markup = merge["markup"].mean()

    score = 100.0
    if avg_markup < 0.10:
        score -= 15
        tips.append(f"å½“å‰å¯æ¯”èœå“å¹³å‡å¤–å–åŠ ä»·ç‡çº¦ **{avg_markup:.0%}**ï¼Œåä½ï¼Œå»ºè®®é€‚å½“æé«˜åˆ° 15% å·¦å³ä»¥è¦†ç›–å¹³å°ä¸é…é€æˆæœ¬ã€‚")
    elif avg_markup > 0.35:
        score -= 20
        tips.append(f"å½“å‰å¯æ¯”èœå“å¹³å‡å¤–å–åŠ ä»·ç‡çº¦ **{avg_markup:.0%}**ï¼Œåé«˜ï¼Œå¯èƒ½å½±å“è½¬åŒ–ç‡ï¼Œå»ºè®®æ§åˆ¶åœ¨ 15%â€“30% åŒºé—´ã€‚")
    else:
        tips.append(f"å½“å‰å¯æ¯”èœå“å¹³å‡å¤–å–åŠ ä»·ç‡çº¦ **{avg_markup:.0%}**ï¼Œæ•´ä½“åˆç†ã€‚")

    tips.append(f"ç”¨äºåˆ†æçš„å¯æ¯”èœå“æ•°é‡ï¼š**{len(merge)}** ä¸ªã€‚")
    return max(score, 0), tips


def compute_promotion_score(has_dd_link: bool, has_ue_link: bool):
    tips = []
    if not has_dd_link and not has_ue_link:
        score = 45.0
        tips.append("æš‚æœªå‘ç° Doordash / UberEats åº—é“ºé“¾æ¥ï¼Œå¤–å–æ¸ é“åŸºç¡€éœ€è¦å…ˆè¡¥é½ã€‚")
    elif has_dd_link and has_ue_link:
        score = 70.0
        tips.append("å·²è¦†ç›–ä¸»æµå¤–å–å¹³å°ï¼Œé€‚åˆåšåˆ†å¹³å°å·®å¼‚åŒ–ä¼˜æƒ ä¸è€å®¢å¤è´­æ´»åŠ¨ã€‚")
    else:
        score = 60.0
        tips.append("å¤–å–å¹³å°ä»…è¦†ç›–éƒ¨åˆ†æ¸ é“ï¼Œå»ºè®®åŒæ­¥æ‹“å±•è‡³ Doordash + UberEatsï¼Œå¹¶ç»Ÿä¸€ä»·æ ¼ä¸æ´»åŠ¨ç­–ç•¥ã€‚")

    tips.append("å½“å‰ç‰ˆæœ¬æœªè¯»å–å…·ä½“æ´»åŠ¨å†…å®¹ï¼Œå»ºè®®åç»­è½åœ°ï¼šé¦–å•å‡å…ã€åˆæ™šé«˜å³°æ»¡å‡ã€è€å®¢åˆ¸åŒ…ç­‰ç»„åˆç©æ³•ï¼ŒæŠŠä¸€æ¬¡æ€§æµé‡å˜æˆå¯å¤è´­ç”¨æˆ·ã€‚")
    return score, tips


def compute_competitor_score(df_comp: pd.DataFrame, restaurant_rating: float):
    tips = []
    if df_comp is None or df_comp.empty or restaurant_rating is None:
        return 60.0, ["ç«å¯¹æˆ–æœ¬åº—è¯„åˆ†æ•°æ®ä¸å®Œæ•´ï¼Œæš‚ç”¨ä¸­æ€§è¯„åˆ†ã€‚"]

    avg_comp_rating = df_comp["rating"].mean()
    diff = restaurant_rating - avg_comp_rating
    score = 60.0 + diff * 10
    score = max(min(score, 100.0), 0.0)

    tips.append(
        f"é™„è¿‘ 600m å†…å…±æ£€æµ‹åˆ° **{len(df_comp)}** å®¶åŒç±»ç«å¯¹é—¨åº—ï¼Œå¹³å‡è¯„åˆ†çº¦ **{avg_comp_rating:.1f}** åˆ†ã€‚"
    )
    if diff >= 0.2:
        tips.append(f"æœ¬åº— Yelp è¯„åˆ† **{restaurant_rating:.1f}**ï¼Œé«˜äºç«å¯¹å‡å€¼ {avg_comp_rating:.1f}ï¼Œå£ç¢‘å…·å¤‡ä¼˜åŠ¿ï¼Œå¯ä»¥åœ¨å¤–å–è¯¦æƒ…é¡µæ›´çªå‡ºã€‚")
    elif diff <= -0.2:
        tips.append(f"æœ¬åº— Yelp è¯„åˆ† **{restaurant_rating:.1f}**ï¼Œä½äºç«å¯¹å‡å€¼ {avg_comp_rating:.1f}ï¼Œå»ºè®®é€šè¿‡æœåŠ¡ä½“éªŒã€åŒ…è£…ã€å¥½è¯„æ¿€åŠ±æ´»åŠ¨å¿«é€Ÿæ‹‰å‡è¯„åˆ†ã€‚")
    else:
        tips.append("æœ¬åº—è¯„åˆ†ä¸é™„è¿‘ç«å¯¹å¤§è‡´æŒå¹³ï¼Œå»ºè®®é€šè¿‡èœå“ç…§ç‰‡ã€æ–‡æ¡ˆä¸æ´»åŠ¨ç©æ³•åšå·®å¼‚åŒ–ã€‚")

    if "distance_km" in df_comp.columns and not df_comp["distance_km"].isna().all():
        tips.append(
            f"å·²æ£€æµ‹åˆ°çš„ç«å¯¹è·ç¦»æœ¬åº—çº¦ **{df_comp['distance_km'].min():.2f}â€“{df_comp['distance_km'].max():.2f} km**ï¼Œ"
            "æ„å‘³ç€ç”¨æˆ·åœ¨åŒä¸€é…é€åŠå¾„å†…æœ‰å¤šå®¶å¯é€‰ã€‚"
        )

    return score, tips


def compute_coverage_score():
    score = 70.0
    tips = [
        "ä»åœ°ç†ä½ç½®å’Œå•†åœˆç»“æ„çš„é€šç”¨ç»éªŒçœ‹ï¼Œé…é€è¦†ç›–å…·å¤‡ä¸€å®šæ½œåŠ›ï¼Œ"
        "åç»­å¯ç»“åˆå®é™…å¹³å°é…é€åŠå¾„ä¸å­¦æ ¡/å†™å­—æ¥¼å¯†åº¦åšè¿›ä¸€æ­¥é‡åŒ–ã€‚"
    ]
    return score, tips


def compute_market_voice_score(yelp_info: dict, place_info: dict):
    """
    å¸‚åœºå£°éŸ³ï¼ˆ0â€“100ï¼‰ï¼šç»¼åˆ Yelp + Google çš„è¯„åˆ† & è¯„è®ºé‡ã€‚
    """
    tips = []

    y_rating = yelp_info.get("rating")
    y_reviews = yelp_info.get("review_count", 0)

    g_rating = None
    g_reviews = 0
    if place_info:
        g_rating = place_info.get("rating")
        g_reviews = place_info.get("user_ratings_total", 0)

    score = 60.0

    if y_rating is not None:
        score += (y_rating - 4.0) * 5
        tips.append(f"Yelp è¯„åˆ†ï¼š**{y_rating:.1f}** åˆ†ï¼Œè¯„è®ºæ•°çº¦ **{y_reviews}** æ¡ã€‚")
    else:
        tips.append("Yelp æš‚æ— è¯„åˆ†æ•°æ®ã€‚")

    if g_rating is not None:
        score += (g_rating - 4.0) * 5
        tips.append(f"Google è¯„åˆ†ï¼š**{g_rating:.1f}** åˆ†ï¼Œè¯„è®ºæ•°çº¦ **{g_reviews}** æ¡ã€‚")
    else:
        tips.append("Google æš‚æ— è¯„åˆ†æ•°æ®æˆ–æœªæ”¶å½•ã€‚")

    total_reviews = (y_reviews or 0) + (g_reviews or 0)
    if total_reviews < 50:
        score -= 5
        tips.append("æ€»ä½“çº¿ä¸Šè¯„è®ºé‡åå°‘ï¼Œå¸‚åœºå£°éŸ³ç›¸å¯¹æœ‰é™ï¼Œå¯é€šè¿‡å¼•å¯¼å¥½è¯„ã€åšæ´»åŠ¨æå‡è¯„è®ºåŸºæ•°ã€‚")
    elif total_reviews > 300:
        score += 5
        tips.append("æ€»ä½“çº¿ä¸Šè¯„è®ºé‡è¾ƒå¤šï¼Œå“ç‰Œåœ¨æœ¬åœ°æœ‰ä¸€å®šâ€œå­˜åœ¨æ„Ÿâ€ï¼Œå¯ä»¥æ”¾å¤§å¤è´­ä¸å£ç¢‘è½¬ä»‹ç»ã€‚")

    score = max(min(score, 100.0), 0.0)
    tips.append("å½“å‰ç‰ˆæœ¬æš‚æœªæ¥å…¥å¤–å–å¹³å°ï¼ˆDoordash/UberEatsï¼‰çš„ç‹¬ç«‹è¯„åˆ†ï¼Œä»…åŸºäº Yelp + Google åšç»Ÿä¸€è¯„ä¼°ã€‚")

    return score, tips


def compute_growth_rate(menu_score, price_score, promo_score, comp_score, coverage_score, voice_score) -> float:
    """å…­å¤§ç»´åº¦åŠ æƒï¼Œæ˜ å°„åˆ° 15%~60% çš„å¢é•¿åŒºé—´ã€‚"""
    weighted = (
        0.18 * menu_score +
        0.12 * price_score +
        0.20 * promo_score +
        0.12 * comp_score +
        0.18 * coverage_score +
        0.20 * voice_score
    ) / 100.0
    growth_rate = MIN_GROWTH + (MAX_GROWTH - MIN_GROWTH) * weighted
    return growth_rate


# ===================== æ ‡å‡†åŒ– Schema + LLM åˆ†æ ===================== #

def build_standard_payload(address: str, result: dict) -> dict:
    """æŠŠè§„åˆ™å¼•æ“çš„ result æ˜ å°„æˆæ ‡å‡†åŒ– JSON ç»“æ„ï¼Œå–‚ç»™å¤§æ¨¡å‹ã€‚"""
    yi = result.get("yelp_info", {}) or {}
    gi = result.get("place_info", {}) or {}
    menus = result.get("menus", {}) or {}
    all_df = menus.get("all")
    comp_df = result.get("competitors")

    # èœå•ç»Ÿè®¡
    total_items = int(len(all_df)) if all_df is not None else 0
    num_categories = 0
    if all_df is not None and "category" in all_df.columns:
        num_categories = int(all_df["category"].nunique())

    prices = []
    if all_df is not None and "price" in all_df.columns:
        prices = [p for p in all_df["price"].tolist() if isinstance(p, (int, float))]
    if prices:
        min_price = float(min(prices))
        max_price = float(max(prices))
        median_price = float(np.median(prices))
    else:
        min_price = max_price = median_price = None

    # ç«å¯¹ç»Ÿè®¡
    num_competitors = 0
    avg_comp_rating = None
    med_comp_rating = None
    if comp_df is not None and not comp_df.empty and "rating" in comp_df.columns:
        num_competitors = int(len(comp_df))
        avg_comp_rating = float(comp_df["rating"].mean())
        med_comp_rating = float(comp_df["rating"].median())

    payload = {
        "meta": {
            "version": "restaurant_schema_v1",
            "generated_at": datetime.datetime.utcnow().isoformat() + "Z"
        },
        "basic_info": {
            "name": yi.get("name") or gi.get("name"),
            "address": yi.get("address") or gi.get("formatted_address") or address,
            "lat": yi.get("lat"),
            "lng": yi.get("lng")
        },
        "online_presence": {
            "yelp": {
                "rating": yi.get("rating"),
                "review_count": yi.get("review_count", 0),
                "price_level": yi.get("price_level"),
                "categories": yi.get("categories", [])
            },
            "google": {
                "rating": gi.get("rating"),
                "review_count": gi.get("user_ratings_total", 0)
            }
        },
        "delivery_channels": {
            "doordash": {
                "has_link": bool(result["delivery_links"].get("doordash")),
                "url": result["delivery_links"].get("doordash")
            },
            "ubereats": {
                "has_link": bool(result["delivery_links"].get("ubereats")),
                "url": result["delivery_links"].get("ubereats")
            }
        },
        "menu": {
            "total_items": total_items,
            "num_categories": num_categories,
            "channels": {
                "dinein_items": int(len(menus.get("dinein"))) if menus.get("dinein") is not None else 0,
                "doordash_items": int(len(menus.get("doordash"))) if menus.get("doordash") is not None else 0,
                "ubereats_items": int(len(menus.get("ubereats"))) if menus.get("ubereats") is not None else 0
            },
            "price_summary": {
                "min_price": min_price,
                "max_price": max_price,
                "median_price": median_price
            }
        },
        "competition": {
            "num_competitors": num_competitors,
            "avg_rating": avg_comp_rating,
            "median_rating": med_comp_rating
        },
        "scores": result.get("scores", {}),
        "growth_estimation": {
            "growth_rate": float(result.get("growth_rate", 0.0)),
            "current_daily_revenue": float(result.get("current_daily_revenue", 0.0)),
            "potential_daily_revenue": float(result.get("potential_daily_revenue", 0.0))
        }
    }
    return payload


def llm_deep_analysis(payload: dict) -> dict:
    """
    ä½¿ç”¨ GPT-5 Responses API è¿›è¡Œæ·±åº¦åˆ†æã€‚
    æ–°ç‰ˆ API ä¸æ”¯æŒ response_formatï¼Œåªèƒ½åœ¨ prompt é‡Œå¼ºåˆ¶æ¨¡å‹è¾“å‡º JSONã€‚
    """
    if client is None:
        return {
            "overall_summary": "æœªé…ç½® OPENAI_API_KEY æˆ–æœªå®‰è£… openai SDKï¼Œå½“å‰ä»…å±•ç¤ºè§„åˆ™å¼•æ“ç»“æœï¼Œæœªå¯ç”¨ AI æ·±åº¦åˆ†æã€‚",
            "key_findings": [],
            "prioritized_actions": [],
            "risks": [],
            "data_gaps": []
        }

    prompt = f"""
ä½ æ˜¯ä¸€ååŒ—ç¾é¤é¥® & å¤–å–è¿è¥ä¸“å®¶ï¼Œç†Ÿæ‚‰ DoorDashã€UberEatsã€ä¸­é¤å…ç»è¥ã€‚

ä¸‹é¢æ˜¯è¯¥é¤å…çš„ç»“æ„åŒ– JSON ä¿¡æ¯ï¼š
{json.dumps(payload, ensure_ascii=False, indent=2)}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯è¾“å‡ºé¤å…çš„æ·±åº¦è¯Šæ–­ç»“æœã€‚

âš ï¸ è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯ ä¸¥æ ¼ JSONï¼Œä¸è¦å‡ºç°å¤šä½™æ–‡å­—ã€ä¸å…è®¸åŠ è§£é‡Šã€ä¸å…è®¸ Markdownã€‚

å›ºå®šè¾“å‡º JSON schema å¦‚ä¸‹ï¼š

{{
  "overall_summary": "stringï¼Œæ•´ä½“æ€»ç»“",
  "key_findings": ["string åˆ—è¡¨ï¼Œæ ¸å¿ƒæ´å¯Ÿ"],
  "prioritized_actions": [
    {{
      "horizon": "short_term æˆ– mid_term",
      "description": "è¡ŒåŠ¨å»ºè®®"
    }}
  ],
  "risks": ["string åˆ—è¡¨ï¼Œä¸»è¦é£é™©ç‚¹"],
  "data_gaps": ["string åˆ—è¡¨ï¼Œç¼ºå¤±çš„æ•°æ®"]
}}

åªè¿”å› JSONï¼Œä¸èƒ½å‡ºç°ä»£ç å—ã€æ³¨é‡Šã€é¢å¤–è¯´æ˜ã€‚
"""

    resp = client.responses.create(
        model="gpt-5.1-mini",
        input=prompt,
        max_output_tokens=1500
    )

    raw_output = resp.output_text

    # å°è¯•è§£æ JSON
    try:
        return json.loads(raw_output)
    except Exception:
        try:
            fixed = raw_output[raw_output.find("{"): raw_output.rfind("}") + 1]
            return json.loads(fixed)
        except Exception:
            return {
                "overall_summary": raw_output,
                "key_findings": [],
                "prioritized_actions": [],
                "risks": [],
                "data_gaps": []
            }


@st.cache_data(show_spinner=False)
def llm_deep_analysis_cached(payload_json_str: str) -> dict:
    """å¸¦ç¼“å­˜çš„ LLM è°ƒç”¨ï¼Œé¿å…åŒä¸€é¤å…åå¤æ‰£è´¹+ç­‰å¾…ã€‚"""
    payload = json.loads(payload_json_str)
    return llm_deep_analysis(payload)


# ===================== æ ¸å¿ƒåˆ†æç®¡çº¿ ===================== #

def analyze_restaurant(address: str, avg_orders: float, avg_ticket: float,
                       yelp_business: dict, fast_mode: bool = False):
    """
    ä¸»å…¥å£ï¼š
    - addressï¼šç”¨æˆ·è¾“å…¥çš„åœ°å€
    - yelp_businessï¼šç”¨æˆ·åœ¨å€™é€‰åˆ—è¡¨ä¸­é€‰æ‹©çš„åº—
    - fast_modeï¼šTrue æ—¶è·³è¿‡èœå•æŠ“å–å’Œ LLMï¼Œåªç”¨äºè§„åˆ™å±‚é¢å¿«é€Ÿè¯„ä¼°
    """
    if not yelp_business:
        raise RuntimeError("æœªæä¾›æœ‰æ•ˆçš„ Yelp / Google åº—é“ºä¿¡æ¯ã€‚")

    yelp_info = yelp_business

    # è®© Google æ›´ç²¾ç¡®ï¼šåº—å + åœ°å€
    place_query = f"{yelp_info['name']} {address}"
    place_info = None
    place = google_find_place(place_query, prefer_restaurant=True, ref_name=yelp_info["name"])
    if place and place.get("place_id"):
        place_info = google_place_details(place["place_id"])

    # ç«å¯¹ï¼ˆYelpï¼‰
    comp_df = fetch_yelp_competitors(yelp_info["lat"], yelp_info["lng"])

    # èœå• & å¤–å–æ¸ é“
    dinein_df = fetch_google_dinein_menu(address)  # ç›®å‰ä¸ºç©ºå ä½

    if fast_mode:
        dd_link = ue_link = None
        dd_df = ue_df = pd.DataFrame(columns=["name", "price", "category", "channel", "tags"])
    else:
        dd_link, ue_link = find_delivery_links(yelp_info["name"], yelp_info["address"])
        dd_df = parse_doordash_menu(dd_link)
        ue_df = parse_ubereats_menu(ue_link)

    if dd_df.empty and ue_df.empty:
        all_df = pd.DataFrame()
    else:
        all_df = pd.concat([dinein_df, dd_df, ue_df], ignore_index=True)

    # å…­å¤§ç»´åº¦
    menu_score, menu_tips = compute_menu_structure_score(all_df)
    price_score, price_tips = compute_pricing_score(dinein_df, dd_df if not dd_df.empty else ue_df)
    promo_score, promo_tips = compute_promotion_score(
        has_dd_link=dd_link is not None, has_ue_link=ue_link is not None
    )
    comp_score, comp_tips = compute_competitor_score(comp_df, yelp_info.get("rating", None))
    coverage_score, coverage_tips = compute_coverage_score()
    voice_score, voice_tips = compute_market_voice_score(yelp_info, place_info)

    growth_rate = compute_growth_rate(
        menu_score, price_score, promo_score, comp_score, coverage_score, voice_score
    )

    current_daily_revenue = avg_orders * avg_ticket
    potential_daily_revenue = current_daily_revenue * (1 + growth_rate)
    revenue_uplift_daily = potential_daily_revenue - current_daily_revenue
    revenue_uplift_monthly = revenue_uplift_daily * 30

    result = {
        "yelp_info": yelp_info,
        "place_info": place_info,
        "competitors": comp_df,
        "delivery_links": {
            "doordash": dd_link,
            "ubereats": ue_link
        },
        "menus": {
            "dinein": dinein_df,
            "doordash": dd_df,
            "ubereats": ue_df,
            "all": all_df
        },
        "scores": {
            "èœå•ç»“æ„": menu_score,
            "å®šä»·ä¸å®¢å•ä»·": price_score,
            "æ´»åŠ¨ä½“ç³»": promo_score,
            "ç«å¯¹å‹åŠ›": comp_score,
            "è¦†ç›–ä¸åœˆå±‚": coverage_score,
            "å¸‚åœºå£°éŸ³": voice_score,
        },
        "tips": {
            "èœå•ç»“æ„": menu_tips,
            "å®šä»·ä¸å®¢å•ä»·": price_tips,
            "æ´»åŠ¨ä½“ç³»": promo_tips,
            "ç«å¯¹å‹åŠ›": comp_tips,
            "è¦†ç›–ä¸åœˆå±‚": coverage_tips,
            "å¸‚åœºå£°éŸ³": voice_tips,
        },
        "growth_rate": growth_rate,
        "current_daily_revenue": current_daily_revenue,
        "potential_daily_revenue": potential_daily_revenue,
        "revenue_uplift_daily": revenue_uplift_daily,
        "revenue_uplift_monthly": revenue_uplift_monthly,
        "fast_mode": fast_mode,
    }

    return result


# ===================== Streamlit çŠ¶æ€åˆå§‹åŒ– ===================== #

if "yelp_candidates" not in st.session_state:
    st.session_state["yelp_candidates"] = []
if "selected_yelp_index" not in st.session_state:
    st.session_state["selected_yelp_index"] = None
if "confirmed_address" not in st.session_state:
    st.session_state["confirmed_address"] = ""


# ===================== UIï¼šç¬¬ä¸€æ­¥ åœ°å€è¾“å…¥ + åŒ¹é…é¤å… ===================== #

st.subheader("ğŸ“ ç¬¬ä¸€æ­¥ï¼šè¾“å…¥åœ°å€å¹¶åŒ¹é…é¤å…")

with st.form("address_form"):
    raw_address = st.text_input(
        "é¤å…åœ°å€ï¼ˆç”¨äºåŒ¹é… Yelp / Google / å¤–å–å¹³å°ï¼‰",
        value=st.session_state.get("confirmed_address", "")
    )
    match_submitted = st.form_submit_button("ğŸ” åŒ¹é…è¯¥åœ°å€ä¸‹çš„é¤å…")

if match_submitted:
    if not raw_address.strip():
        st.error("è¯·è¾“å…¥é¤å…åœ°å€ã€‚")
    else:
        with st.spinner("æ­£åœ¨æ ¹æ®åœ°å€åŒ¹é… Yelp é¤å…ï¼Œè¯·ç¨ç­‰..."):
            candidates = fetch_yelp_candidates_by_address(raw_address)

        if not candidates:
            place = google_find_place(raw_address, prefer_restaurant=True)
            if place:
                types = place.get("types", []) or []

                primary_food_types = {"restaurant", "food", "meal_takeaway", "meal_delivery"}
                secondary_food_types = {"cafe", "bar", "bakery"}

                is_primary = any(t in primary_food_types for t in types)
                is_secondary = any(t in secondary_food_types for t in types)

                if is_primary or is_secondary:
                    details = google_place_details(place["place_id"])
                    loc = place["geometry"]["location"]

                    google_candidate = {
                        "id": None,
                        "name": details.get("name", place.get("name", "Unknown Business")),
                        "rating": details.get("rating", None),
                        "review_count": details.get("user_ratings_total", 0),
                        "price_level": details.get("price_level", ""),
                        "categories": types,
                        "categories_str": ", ".join(types) if types else "Google Place",
                        "lat": loc["lat"],
                        "lng": loc["lng"],
                        "address": details.get("formatted_address", raw_address),
                        "source": "google",
                    }
                    candidates = [google_candidate]

        st.session_state["confirmed_address"] = raw_address
        st.session_state["yelp_candidates"] = candidates
        st.session_state["selected_yelp_index"] = 0 if candidates else None

candidates = st.session_state.get("yelp_candidates", [])
selected_biz = None

if candidates:
    st.success("å·²åœ¨è¯¥åœ°å€é™„è¿‘åŒ¹é…åˆ°ä»¥ä¸‹é¤å…ï¼Œè¯·é€‰æ‹©è¦è¯Šæ–­çš„ä¸€å®¶ï¼š")

    options = list(range(len(candidates)))

    def format_option(i):
        b = candidates[i]
        source = b.get("source", "yelp")
        source_tag = "Yelp" if source == "yelp" else "Google"
        return f"{b['name']} Â· {b['categories_str']} Â· â­ {b.get('rating', 'N/A')} Â· {b['address']} Â· {source_tag}"

    selected_index = st.radio(
        "åŒ¹é…é¤å…",
        options,
        format_func=format_option,
        index=st.session_state.get("selected_yelp_index", 0)
    )
    st.session_state["selected_yelp_index"] = selected_index
    selected_biz = candidates[selected_index]

    st.info(
        f"å½“å‰å·²é€‰æ‹©ï¼š**{selected_biz['name']}**ï¼ˆ{selected_biz['address']}ï¼‰ã€‚"
        "ç‚¹å‡»ä¸‹æ–¹â€œå¼€å§‹è¯Šæ–­â€å‰ï¼Œå¯ä»¥å…ˆç¡®è®¤æ˜¯å¦æ˜¯ä½ è¦åˆ†æçš„é‚£å®¶åº—ã€‚"
    )

elif st.session_state["confirmed_address"]:
    st.error("è¯¥åœ°å€é™„è¿‘æœªåœ¨ Yelp / Google æ‰¾åˆ°é¤å…ä¸šåŠ¡ï¼Œå¯èƒ½ä¸æ˜¯é¤å…åœ°å€æˆ–æœªç™»è®°ä¸ºé¤é¥®é—¨åº—ã€‚")


# ===================== UIï¼šç¬¬äºŒæ­¥ è¾“å…¥ä¸šåŠ¡æ•°æ® + å¼€å§‹è¯Šæ–­ ===================== #

st.subheader("ğŸ“Š ç¬¬äºŒæ­¥ï¼šè¾“å…¥å½“å‰å¤–å–æ•°æ®ï¼Œç”Ÿæˆè¯Šæ–­ç»“æœ")

with st.form("diagnose_form"):
    col1, col2 = st.columns(2)
    with col1:
        avg_orders = st.number_input("å½“å‰æ—¥å‡å¤–å–å•é‡ï¼ˆå•ï¼‰", min_value=0.0, value=40.0, step=1.0)
    with col2:
        avg_ticket = st.number_input("å½“å‰å¤–å–å®¢å•ä»·ï¼ˆç¾å…ƒï¼‰", min_value=0.0, value=25.0, step=1.0)

    fast_mode = st.checkbox("âš¡ å¿«é€Ÿè¯Šæ–­æ¨¡å¼ï¼ˆè·³è¿‡èœå•æŠ“å– & å¤§æ¨¡å‹åˆ†æï¼Œæå‡é€Ÿåº¦ï¼‰", value=True)

    start_diagnose = st.form_submit_button("ğŸš€ å¼€å§‹è¯Šæ–­")

if start_diagnose:
    if not selected_biz:
        st.error("è¯·å…ˆåœ¨ä¸Šæ–¹åŒ¹é…å¹¶é€‰æ‹©ä¸€å®¶é¤å…ã€‚å½“å‰åœ°å€å¯èƒ½ä¸æ˜¯é¤å…ï¼Œæˆ–è€… Yelp / Google ä¸Šæ²¡æœ‰ç›¸å…³åº—é“ºã€‚")
    else:
        try:
            with st.spinner("æ­£åœ¨åŸºäº Yelp / Google / å¤–å–å¹³å°æ•°æ®è¿›è¡Œè¯Šæ–­..."):
                result = analyze_restaurant(
                    st.session_state["confirmed_address"],
                    avg_orders,
                    avg_ticket,
                    yelp_business=selected_biz,
                    fast_mode=fast_mode,
                )

            # é¡¶éƒ¨ KPI
            st.subheader("ğŸ“Œ è¯Šæ–­ç»“æœæ€»è§ˆ")

            col_a, col_b, col_c = st.columns(3)
            with col_a:
                st.metric("å½“å‰æ—¥å¤–å–è¥ä¸šé¢ï¼ˆä¼°ç®—ï¼‰", f"${result['current_daily_revenue']:.0f}")
            with col_b:
                st.metric("ä¼˜åŒ–åæ—¥å¤–å–è¥ä¸šé¢ï¼ˆé¢„æµ‹ï¼‰", f"${result['potential_daily_revenue']:.0f}")
            with col_c:
                st.metric("æœˆåº¦å¯æå‡å¤–å–è¥ä¸šé¢ï¼ˆé¢„æµ‹ï¼‰", f"+${result['revenue_uplift_monthly']:.0f}")

            st.write(
                f"ç»¼åˆèœå•ç»“æ„ã€å®šä»·ç­–ç•¥ã€æ´»åŠ¨ä½“ç³»ã€ç«å¯¹å‹åŠ›ã€è¦†ç›–åœˆå±‚ä¸å¸‚åœºå£°éŸ³ï¼Œ"
                f"ç³»ç»Ÿé¢„ä¼°é€šè¿‡ç²¾ç»†åŒ–è¿è¥ï¼Œå¯å¸¦æ¥çº¦ **{result['growth_rate']*100:.1f}%** çš„å¤–å–è¥ä¸šé¢å¢é•¿ç©ºé—´ã€‚"
            )

            # å…­å¤§ç»´åº¦è¯„åˆ†
            st.subheader("ğŸ§¬ å…­å¤§ç»´åº¦è¯Šæ–­è¯„åˆ†")
            score_df = pd.DataFrame(
                {"ç»´åº¦": list(result["scores"].keys()),
                 "å¾—åˆ†": list(result["scores"].values())}
            )
            st.bar_chart(score_df.set_index("ç»´åº¦"))

            # ===== AI æ·±åº¦è¯Šæ–­ï¼ˆä»…åœ¨éå¿«é€Ÿæ¨¡å¼ä¸‹å¯ç”¨ï¼‰ =====
            if not fast_mode:
                payload = build_standard_payload(
                    st.session_state["confirmed_address"],
                    result
                )
                payload_str = json.dumps(payload, ensure_ascii=False, sort_keys=True)
                with st.spinner("æ­£åœ¨è°ƒç”¨ AI è¿›è¡Œæ·±åº¦é€»è¾‘åˆ†æ..."):
                    ai_analysis = llm_deep_analysis_cached(payload_str)

                st.subheader("ğŸ§  AI æ·±åº¦è¯Šæ–­ï¼ˆå¤§æ¨¡å‹åˆ†æï¼‰")
                tab_ai, tab_data = st.tabs(["AI è¯Šæ–­ç»“è®º", "ç‰¹å¾ JSON"])

                with tab_ai:
                    st.markdown(f"**æ•´ä½“æ€»ç»“ï¼š** {ai_analysis.get('overall_summary', '')}")

                    st.markdown("**å…³é”®å‘ç°ï¼š**")
                    for item in ai_analysis.get("key_findings", []):
                        st.markdown(f"- {item}")

                    st.markdown("**ä¼˜å…ˆè¡ŒåŠ¨æ¸…å•ï¼š**")
                    for act in ai_analysis.get("prioritized_actions", []):
                        st.markdown(f"- [{act.get('horizon', 'short_term')}] {act.get('description','')}")

                    st.markdown("**æ½œåœ¨é£é™©ç‚¹ï¼š**")
                    for r in ai_analysis.get("risks", []):
                        st.markdown(f"- {r}")

                    st.markdown("**æ•°æ®ç¼ºå£ï¼ˆå»ºè®®è¡¥å……ï¼‰ï¼š**")
                    for g in ai_analysis.get("data_gaps", []):
                        st.markdown(f"- {g}")

                with tab_data:
                    st.code(json.dumps(payload, indent=2, ensure_ascii=False), language="json")
            else:
                st.info("å½“å‰ä¸ºâš¡å¿«é€Ÿè¯Šæ–­æ¨¡å¼ï¼šå·²è·³è¿‡èœå•æŠ“å–ä¸å¤§æ¨¡å‹åˆ†æï¼Œåªå±•ç¤ºåŸºç¡€è¯„åˆ†ä¸ç«å¯¹ã€‚")

            # åˆ†ç»´åº¦å»ºè®® + å…·ä½“åˆ†æ
            st.subheader("ğŸ©º åˆ†ç»´åº¦è¿è¥å»ºè®®ï¼ˆç‚¹å‡»å±•å¼€æŸ¥çœ‹è¯¦ç»†åˆ†æï¼‰")
            for dim, tips in result["tips"].items():
                with st.expander(f"{dim} Â· è¯Šæ–­ä¸åˆ†ææ¦‚è§ˆ"):
                    for t in tips:
                        st.markdown(f"- {t}")

                    if dim == "ç«å¯¹å‹åŠ›":
                        comp_df = result["competitors"]
                        if comp_df is not None and not comp_df.empty:
                            st.markdown("**é™„è¿‘ç«å¯¹æ¦‚è§ˆï¼š**")
                            st.write(
                                f"- ç«å¯¹æ•°é‡ï¼š**{len(comp_df)}** å®¶\n"
                                f"- è¯„åˆ†ä¸­ä½æ•°ï¼š**{comp_df['rating'].median():.1f}**\n"
                            )
                            if "distance_km" in comp_df.columns:
                                st.write(
                                    f"- è·ç¦»èŒƒå›´ï¼šçº¦ **{comp_df['distance_km'].min():.2f}â€“{comp_df['distance_km'].max():.2f} km**"
                                )
                            st.markdown("**è¯„åˆ†æœ€é«˜çš„å‰ 5 å®¶ç«å¯¹ï¼š**")
                            st.dataframe(
                                comp_df.sort_values("rating", ascending=False)
                                .head(5)[["name", "rating", "review_count", "price_level", "distance_km", "categories"]]
                            )
                        else:
                            st.write("æœªè·å–åˆ°ç«å¯¹æ•°æ®ã€‚")

                    if dim == "èœå•ç»“æ„":
                        all_df = result["menus"]["all"]
                        if all_df is not None and not all_df.empty:
                            st.markdown("**èœå•ç»“æ„æ¦‚è§ˆï¼š**")
                            st.write(f"- å¤–å– & å ‚é£Ÿåˆè®¡èœå“æ•°ï¼š**{len(all_df)}** ä¸ª")
                            if "category" in all_df.columns:
                                st.write(f"- ç±»ç›®æ•°é‡ï¼š**{all_df['category'].nunique()}** ä¸ª")
                                st.markdown("**å„ç±»ç›®èœå“æ•° Top5ï¼š**")
                                st.dataframe(
                                    all_df.groupby("category")["name"]
                                    .count()
                                    .sort_values(ascending=False)
                                    .head(5)
                                    .rename("èœå“æ•°")
                                )
                        else:
                            st.write("æœªè·å–åˆ°èœå•ç»“æ„æ•°æ®ã€‚")

                    if dim == "å¸‚åœºå£°éŸ³":
                        yi = result["yelp_info"]
                        gi = result.get("place_info")
                        st.markdown("**çº¿ä¸Šå£ç¢‘æ€»è§ˆï¼š**")
                        if yi:
                            st.write(
                                f"- Yelpï¼šè¯„åˆ† **{yi.get('rating', 'N/A')}**ï¼Œè¯„è®º **{yi.get('review_count', 0)}** æ¡"
                            )
                        if gi:
                            st.write(
                                f"- Googleï¼šè¯„åˆ† **{gi.get('rating', 'N/A')}**ï¼Œè¯„è®º **{gi.get('user_ratings_total', 0)}** æ¡"
                            )

                        total_reviews = (yi.get("review_count", 0) if yi else 0) + (
                            gi.get("user_ratings_total", 0) if gi else 0
                        )
                        st.write(f"- Yelp + Google æ€»è¯„è®ºé‡çº¦ï¼š**{total_reviews}** æ¡")

                        st.markdown(
                            "**ç­–ç•¥å»ºè®®ï¼š** å¯ä»¥åœ¨é—¨åº—æ¡Œç‰Œã€æ”¶æ®ã€å¤–å–è´´çº¸ä¸Šåšâ€œå¥½è¯„è¿”åˆ¸/ç§¯åˆ†â€æ´»åŠ¨ï¼Œ"
                            "è®©è¯„è®ºé‡æ›´å¿«ç ´ 300 ä»¥ä¸Šï¼ŒæŠŠâ€œå¸‚åœºå£°éŸ³â€åšæˆçœŸå®çš„æŠ•æ”¾èµ„äº§ã€‚"
                        )

            # åŸºæœ¬ä¿¡æ¯
            st.subheader("ğŸª åº—é“ºåŸºç¡€ä¿¡æ¯ï¼ˆæ¥è‡ª Yelp / Googleï¼‰")
            col_y1, col_y2 = st.columns(2)
            with col_y1:
                st.markdown("**Yelp ä¿¡æ¯**")
                yi = result["yelp_info"]
                st.write(f"åº—åï¼š{yi['name']}")
                st.write(f"åœ°å€ï¼š{yi['address']}")
                st.write(f"è¯„åˆ†ï¼š{yi.get('rating', 'N/A')} â­ï¸ï¼ˆ{yi.get('review_count', 0)} æ¡è¯„è®ºï¼‰")
                st.write(f"ä»·æ ¼ç­‰çº§ï¼š{yi.get('price_level', 'N/A')}")
                st.write(f"å“ç±»ï¼š{', '.join(yi.get('categories', []))}")
            with col_y2:
                st.markdown("**Google Place ä¿¡æ¯ï¼ˆè‹¥åŒ¹é…æˆåŠŸï¼‰**")
                gi = result.get("place_info")
                if gi:
                    st.write(f"åº—åï¼š{gi.get('name', 'N/A')}")
                    st.write(f"åœ°å€ï¼š{gi.get('formatted_address', 'N/A')}")
                    st.write(f"è¯„åˆ†ï¼š{gi.get('rating', 'N/A')} â­ï¸ï¼ˆ{gi.get('user_ratings_total', 0)} æ¡è¯„è®ºï¼‰")
                else:
                    st.write("æœªä» Google Places æ‰¾åˆ°æ›´å¤šè¯¦æƒ…ã€‚")

            # å¤–å–å¹³å°é“¾æ¥
            st.subheader("ğŸšš å¤–å–å¹³å°è¦†ç›–æƒ…å†µ")
            dl = result["delivery_links"]
            if dl["doordash"]:
                st.markdown(f"- âœ… Doordashï¼š[{dl['doordash']}]({dl['doordash']})")
            else:
                st.markdown("- âŒ æœªå‘ç° Doordash åº—é“ºé“¾æ¥")
            if dl["ubereats"]:
                st.markdown(f"- âœ… UberEatsï¼š[{dl['ubereats']}]({dl['ubereats']})")
            else:
                st.markdown("- âŒ æœªå‘ç° UberEats åº—é“ºé“¾æ¥")

            # èœå•æ•°æ®
            st.subheader("ğŸ“‘ èœå•æ•°æ®ï¼ˆè‹¥è§£ææˆåŠŸï¼‰")
            tab1, tab2, tab3, tab4 = st.tabs(["å ‚é£Ÿï¼ˆGoogleï¼‰", "Doordash èœå•", "UberEats èœå•", "æ•´åˆè§†å›¾"])
            with tab1:
                if result["menus"]["dinein"].empty:
                    st.write("å½“å‰ç‰ˆæœ¬æœªä» Google è§£æç»“æ„åŒ–å ‚é£Ÿèœå•ã€‚")
                else:
                    st.dataframe(result["menus"]["dinein"])
            with tab2:
                if result["menus"]["doordash"].empty:
                    st.write("æœªè§£æåˆ° Doordash èœå•ç»“æ„ã€‚")
                else:
                    st.dataframe(result["menus"]["doordash"])
            with tab3:
                if result["menus"]["ubereats"].empty:
                    st.write("æœªè§£æåˆ° UberEats èœå•ç»“æ„ã€‚")
                else:
                    st.dataframe(result["menus"]["ubereats"])
            with tab4:
                if result["menus"]["all"].empty:
                    st.write("æš‚æ— å¯ç”¨èœå•æ•°æ®ã€‚")
                else:
                    st.dataframe(result["menus"]["all"])

            # ç«å¯¹åˆ—è¡¨
            st.subheader("ğŸ é™„è¿‘ç«å¯¹é—¨åº—åˆ—è¡¨ï¼ˆæ¥è‡ª Yelpï¼‰")
            if result["competitors"].empty:
                st.write("æœªè·å–åˆ°ç«å¯¹æ•°æ®ã€‚")
            else:
                st.dataframe(result["competitors"])

            st.info(
                "å½“å‰ç‰ˆæœ¬ï¼šå…ˆç”± Yelp + åæ ‡åŒ¹é…é¤å…ï¼Œè‹¥å¤±è´¥åˆ™ç”± Google Places å…œåº•ï¼›"
                "åªæœ‰å½“ Yelp å’Œ Google éƒ½æ— æ³•è¯†åˆ«ä¸ºé¤é¥®é—¨åº—æ—¶ï¼Œæ‰ä¼šæç¤ºâ€œè¯¥åœ°å€ä¸æ˜¯é¤å…â€ã€‚"
            )

        except Exception as e:
            st.error(f"è¯Šæ–­è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{e}")

else:
    st.markdown(
        """
        ### ä½¿ç”¨è¯´æ˜
        1. åœ¨ä¸Šæ–¹è¾“å…¥é¤å…åœ°å€å¹¶ç‚¹å‡»ã€ŒåŒ¹é…è¯¥åœ°å€ä¸‹çš„é¤å…ã€  
        2. ä»å€™é€‰åˆ—è¡¨ä¸­é€‰ä¸­ä½ çš„é¤å…  
        3. è¾“å…¥å½“å‰æ—¥å‡å¤–å–å•é‡ & å®¢å•ä»·ï¼Œé€‰æ‹©æ˜¯å¦å¼€å¯âš¡å¿«é€Ÿè¯Šæ–­æ¨¡å¼ï¼Œç‚¹å‡»ã€Œå¼€å§‹è¯Šæ–­ã€  
        4. å¿«é€Ÿæ¨¡å¼ä¸‹åªçœ‹åŸºç¡€ç›˜å­ï¼›å…³é—­å¿«é€Ÿæ¨¡å¼åˆ™ä¼šæŠ“èœå• + è°ƒå¤§æ¨¡å‹å‡ºä¸€ä»½æ·±åº¦æŠ¥å‘Š  
        """
    )

# ========== ç½²åï¼ˆLinkedInï¼‰ ==========
LINKEDIN_URL = "https://www.linkedin.com/in/lingyu-maxwell-lai"
st.markdown(
    f"""
<div style="display:flex;align-items:center;gap:10px;margin-top:-6px;margin-bottom:8px;">
  <div style="font-size:14px;color:#666;">
    Builded by <strong>Maxwell Lai</strong>
  </div>
  <a href="{LINKEDIN_URL}" target="_blank" title="LinkedIn: Maxwell Lai"
     style="display:inline-flex;align-items:center;justify-content:center;width:18px;height:18px;
            border-radius:4px;background:#0A66C2;">
    <img src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons/icons/linkedin.svg"
         alt="LinkedIn" width="12" height="12" style="filter: invert(1);" />
  </a>
</div>
""",
    unsafe_allow_html=True,
)