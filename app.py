import streamlit as st
import pandas as pd
import requests
import googlemaps
from bs4 import BeautifulSoup
from urllib.parse import urlparse
from typing import List, Dict, Any, Optional
import math
import time

# ---------------------------
# åŸºç¡€é…ç½®
# ---------------------------
st.set_page_config(
    page_title="Restaurant Local SEO & Competitor Analyzer",
    layout="wide",
)

st.title("ğŸœ Restaurant Local SEO & Competitor Analyzer")
st.write(
    "å¤åˆ¶ Owner.com é£æ ¼çš„æœ¬åœ°é¤å…åœ¨çº¿å¥åº·æ£€æŸ¥ï¼š\n"
    "- è‡ªåŠ¨æ‰¾ç«äº‰å¯¹æ‰‹\n"
    "- è¯„ä¼° Google å•†å®¶èµ„æ–™å®Œæ•´åº¦\n"
    "- æ£€æŸ¥ç½‘ç«™å†…å®¹/SEO åŸºç¡€\n"
    "- æ¨¡æ‹Ÿæœ¬åœ°æœç´¢æ’å\n"
    "- ç²—ç®—æ½œåœ¨è¥æ”¶æŸå¤±"
)

# ---------------------------
# ä¾§è¾¹æ ï¼šAPI Key & å‚æ•°
# ---------------------------
# ---------------------------
# ä» secrets è¯»å– API Key
# ---------------------------
GOOGLE_API_KEY = st.secrets.get("GOOGLE_API_KEY", "")
SERPAPI_KEY = st.secrets.get("SERPAPI_KEY", "")
YELP_API_KEY = st.secrets.get("YELP_API_KEY", "")
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", "")  # ä»¥åè¦ç”¨å¯ä»¥ç›´æ¥æ‹¿

if not GOOGLE_API_KEY:
    st.error("ç¼ºå°‘ GOOGLE_API_KEYï¼Œè¯·åœ¨ Streamlit Secrets ä¸­é…ç½®ã€‚")
    st.stop()

default_radius_km = st.sidebar.slider(
    "ç«äº‰å¯¹æ‰‹æœç´¢åŠå¾„ï¼ˆå…¬é‡Œï¼‰", 0.5, 10.0, 3.0, 0.5
)

avg_order_value = st.sidebar.number_input(
    "å¹³å‡å®¢å•ä»·ï¼ˆUSDï¼‰", min_value=5.0, max_value=200.0, value=40.0, step=1.0
)
assumed_ctr = st.sidebar.slider(
    "ç‚¹å‡»ç‡å‡è®¾ï¼ˆç”¨æˆ·çœ‹åˆ°ä½ çš„ç»“æœåç‚¹è¿›æ¥çš„æ¯”ä¾‹ï¼‰",
    0.05, 0.5, 0.15, 0.01
)
assumed_conv = st.sidebar.slider(
    "ä¸‹å•è½¬åŒ–ç‡å‡è®¾ï¼ˆç‚¹è¿›ç½‘ç«™/èµ„æ–™åä¸‹å•çš„æ¯”ä¾‹ï¼‰",
    0.05, 0.5, 0.2, 0.01
)

st.sidebar.markdown("---")



# ---------------------------
# å·¥å…·å‡½æ•°ï¼ˆç¼“å­˜ï¼‰
# ---------------------------

@st.cache_data(show_spinner=False)
def gm_client(key: str):
    return googlemaps.Client(key=key)


@st.cache_data(show_spinner=False)
def google_places_search(api_key: str, query: str) -> List[Dict[str, Any]]:
    gmaps = gm_client(api_key)
    result = gmaps.places(query=query)
    return result.get("results", [])


@st.cache_data(show_spinner=False)
def google_place_details(api_key: str, place_id: str) -> Dict[str, Any]:
    gmaps = gm_client(api_key)
    fields = [
        "name",
        "formatted_address",
        "formatted_phone_number",
        "geometry",
        "rating",
        "user_ratings_total",
        "types",
        "opening_hours",
        "website",
        "price_level",
        "photos",
    ]
    result = gmaps.place(place_id=place_id, fields=fields)
    return result.get("result", {})


@st.cache_data(show_spinner=False)
def google_places_nearby(
    api_key: str, lat: float, lng: float, radius_m: int, type_: str = "restaurant"
) -> List[Dict[str, Any]]:
    gmaps = gm_client(api_key)
    result = gmaps.places_nearby(
        location=(lat, lng), radius=radius_m, type=type_
    )
    return result.get("results", [])


@st.cache_data(show_spinner=False)
def fetch_html(url: str) -> Optional[str]:
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Restaurant-Analyzer)"}
        resp = requests.get(url, headers=headers, timeout=10)
        if resp.status_code == 200:
            return resp.text
        return None
    except Exception:
        return None


@st.cache_data(show_spinner=False)
def serpapi_google_maps_search(
    serpapi_key: str, query: str, lat: float, lng: float, zoom: float = 13.0
) -> Dict[str, Any]:
    """
    ä½¿ç”¨ SerpAPI çš„ Google Maps å¼•æ“åšçœŸå®æœ¬åœ°æœç´¢ã€‚
    éœ€è¦ä»˜è´¹/é™é¢ï¼Œç”¨æˆ·è‡ªè¡Œç”³è¯· keyã€‚
    """
    url = "https://serpapi.com/search"
    ll_param = f"@{lat},{lng},{zoom}z"
    params = {
        "engine": "google_maps",
        "type": "search",
        "q": query,
        "ll": ll_param,
        "api_key": serpapi_key,
    }
    resp = requests.get(url, params=params, timeout=30)
    resp.raise_for_status()
    return resp.json()


# ---------------------------
# è¯„åˆ†å‡½æ•°
# ---------------------------

def score_gbp_profile(place: Dict[str, Any]) -> Dict[str, Any]:
    """
    ç®€åŒ–ç‰ˆ Google å•†å®¶èµ„æ–™è¯„åˆ†ï¼Œæ€»åˆ† 40 åˆ†ã€‚
    ä½ å¯ä»¥æ ¹æ®è‡ªå·±ç­–ç•¥ç»§ç»­ç»†åŒ–ã€‚
    """
    score = 0
    checks = {}

    # 1. åç§° & åœ°å€
    has_name = bool(place.get("name"))
    has_address = bool(place.get("formatted_address"))
    pts = 4 if (has_name and has_address) else 0
    score += pts
    checks["åç§°/åœ°å€å®Œæ•´"] = (pts, has_name and has_address)

    # 2. ç”µè¯
    has_phone = bool(place.get("formatted_phone_number"))
    pts = 4 if has_phone else 0
    score += pts
    checks["ç”µè¯"] = (pts, has_phone)

    # 3. è¥ä¸šæ—¶é—´
    opening_hours = place.get("opening_hours", {})
    has_hours = bool(opening_hours.get("weekday_text")) or opening_hours.get(
        "open_now"
    ) is not None
    pts = 4 if has_hours else 0
    score += pts
    checks["è¥ä¸šæ—¶é—´"] = (pts, has_hours)

    # 4. ç½‘ç«™
    has_website = bool(place.get("website"))
    pts = 4 if has_website else 0
    score += pts
    checks["ç½‘ç«™é“¾æ¥"] = (pts, has_website)

    # 5. è¯„åˆ† & è¯„è®ºæ•°
    rating = place.get("rating")
    reviews = place.get("user_ratings_total", 0)
    has_reviews = rating is not None and reviews >= 10
    pts = 6 if has_reviews else 0
    score += pts
    checks["è¯„åˆ† & â‰¥10æ¡è¯„è®º"] = (pts, has_reviews)

    # 6. ç±»åˆ«
    types_ = place.get("types", [])
    has_category = any(t for t in types_ if t != "point_of_interest")
    pts = 6 if has_category else 0
    score += pts
    checks["ç±»åˆ«è®¾ç½®"] = (pts, has_category)

    # 7. ä»·æ ¼ç­‰çº§
    has_price_level = place.get("price_level") is not None
    pts = 4 if has_price_level else 0
    score += pts
    checks["ä»·æ ¼åŒºé—´"] = (pts, has_price_level)

    # 8. ç…§ç‰‡
    photos = place.get("photos", [])
    has_photos = len(photos) > 0
    pts = 8 if has_photos else 0
    score += pts
    checks["ç…§ç‰‡/å›¾ç‰‡"] = (pts, has_photos)

    return {"score": score, "checks": checks}


def score_website_basic(url: str, html: Optional[str]) -> Dict[str, Any]:
    """
    ç®€åŒ–ç‰ˆç½‘ç«™è¯„åˆ†ï¼Œæ€»åˆ† 40 åˆ†ã€‚
    ä¸»è¦çœ‹ SEO åŸºç¡€ + æ–‡æœ¬é‡ + æ˜¯å¦æœ‰å…³é”®è¯ç­‰ã€‚
    """
    if not url or not html:
        return {
            "score": 0,
            "checks": {"æ— æ³•è®¿é—®ç½‘ç«™": (0, False)},
        }

    soup = BeautifulSoup(html, "lxml")
    score = 0
    checks = {}

    # 1. Title
    title = soup.title.string.strip() if soup.title and soup.title.string else ""
    has_title = bool(title)
    pts = 6 if has_title else 0
    score += pts
    checks["æœ‰é¡µé¢æ ‡é¢˜ï¼ˆtitleï¼‰"] = (pts, has_title)

    # 2. Meta Description
    desc_tag = soup.find("meta", attrs={"name": "description"})
    has_desc = bool(desc_tag and desc_tag.get("content"))
    pts = 6 if has_desc else 0
    score += pts
    checks["æœ‰ Meta Description"] = (pts, has_desc)

    # 3. H1
    h1 = soup.find("h1")
    has_h1 = bool(h1 and h1.get_text(strip=True))
    pts = 4 if has_h1 else 0
    score += pts
    checks["æœ‰ H1 æ ‡é¢˜"] = (pts, has_h1)

    # 4. æ–‡æœ¬æ€»é‡
    texts = soup.get_text(separator=" ", strip=True)
    word_count = len(texts.split())
    has_sufficient_text = word_count >= 300
    pts = 8 if has_sufficient_text else 0
    score += pts
    checks["æ–‡æœ¬é‡ â‰¥ 300 è¯"] = (pts, has_sufficient_text)

    # 5. è”ç³»æ–¹å¼
    has_phone_text = any(x in texts for x in ["(", ")", "-", "+1"])
    pts = 4 if has_phone_text else 0
    score += pts
    checks["é¡µé¢ä¸Šèƒ½çœ‹åˆ°ç”µè¯"] = (pts, has_phone_text)

    # 6. èœå“/é¤å…å…³é”®è¯ï¼ˆç®€å•åŒ¹é…ï¼‰
    keywords = ["chinese", "asian", "noodle", "rice", "dumpling", "chicken"]
    kw_hit = any(kw.lower() in texts.lower() for kw in keywords)
    pts = 6 if kw_hit else 0
    score += pts
    checks["æ–‡æœ¬åŒ…å«èœå“/èœç³»å…³é”®è¯"] = (pts, kw_hit)

    # 7. https
    parsed = urlparse(url)
    has_https = parsed.scheme == "https"
    pts = 6 if has_https else 0
    score += pts
    checks["ä½¿ç”¨ HTTPS"] = (pts, has_https)

    return {"score": score, "checks": checks, "word_count": word_count, "title": title}


def estimate_revenue_loss(
    monthly_search_volume: int,
    rank_bucket: str,
    avg_order_value: float,
    ctr: float,
    conv: float,
) -> float:
    """
    éç²¾ç¡®æ¨¡å‹ï¼Œåªæ˜¯ç»™è€æ¿ä¸€ä¸ªå¤§æ¦‚æ„Ÿè§‰ã€‚
    ç®€å•æœºåˆ¶ï¼š
    - Top 3ï¼šå¯ä»¥åƒåˆ° 100% æ½œåœ¨æµé‡
    - 4-10ï¼šåªèƒ½åƒåˆ° 40%
    - æœªä¸Šæ¦œï¼š10%
    ç”¨è¿™ä¸ªå¯¹æ¯”â€œç†æƒ³çŠ¶æ€ vs å½“å‰çŠ¶æ€â€çš„å·®é¢ã€‚
    """
    ideal_customers = monthly_search_volume * ctr * conv
    if rank_bucket == "top3":
        current_factor = 1.0
    elif rank_bucket == "4-10":
        current_factor = 0.4
    else:
        current_factor = 0.1

    current_customers = ideal_customers * current_factor
    potential_extra_customers = ideal_customers - current_customers
    monthly_loss = potential_extra_customers * avg_order_value
    return monthly_loss


def infer_rank_from_serpapi(
    serp_json: Dict[str, Any], business_name: str
) -> Optional[int]:
    """
    ä» SerpAPI Google Maps ç»“æœä¸­æ‰¾åˆ°å½“å‰é¤å…çš„åæ¬¡ã€‚
    """
    results = serp_json.get("local_results") or serp_json.get("places_results") or []
    for idx, res in enumerate(results, start=1):
        name = res.get("title") or res.get("name", "")
        if name and business_name.lower() in name.lower():
            return idx
    return None


# ---------------------------
# ä¸»äº¤äº’ï¼šè¾“å…¥é¤å…ä¿¡æ¯
# ---------------------------

st.markdown("## 1ï¸âƒ£ è¾“å…¥é¤å…ä¿¡æ¯")

col1, col2 = st.columns(2)
with col1:
    restaurant_name = st.text_input("é¤å…åç§°ï¼ˆRestaurant Nameï¼‰", "")
with col2:
    city_region = st.text_input("åŸå¸‚/åŒºåŸŸï¼ˆä¾‹å¦‚ï¼šOuter Sunset, San Franciscoï¼‰", "")

website_url = st.text_input(
    "é¤å…å®˜ç½‘ URLï¼ˆå¦‚ https://example.comï¼‰",
    "",
)

keywords_input = st.text_input(
    "æ ¸å¿ƒå…³é”®è¯ï¼ˆé€—å·åˆ†éš”ï¼Œä¾‹å¦‚ï¼šbest chinese food outer sunset, best asian food west portalï¼‰",
    "best chinese food outer sunset, best asian food outer sunset",
)

monthly_search_volume = st.number_input(
    "ä¼°ç®—æ¯ä¸ªæ ¸å¿ƒå…³é”®è¯çš„æœˆæœç´¢é‡ï¼ˆç²—ç•¥ç»Ÿä¸€å€¼ï¼‰",
    min_value=50,
    max_value=50000,
    value=500,
    step=50,
    help="æ›´ç²¾ç¡®å¯ä»¥ä»¥åæ¥ Google Ads Keyword Planner æˆ–ç¬¬ä¸‰æ–¹å…³é”®è¯ APIã€‚",
)

run_btn = st.button("ğŸš€ è¿è¡Œåˆ†æ")

if run_btn:
    if not google_api_key:
        st.error("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ Google API Keyã€‚")
        st.stop()

    if not restaurant_name or not city_region:
        st.error("è¯·å¡«å†™é¤å…åç§°å’ŒåŸå¸‚/åŒºåŸŸã€‚")
        st.stop()

    query = f"{restaurant_name} {city_region}"
    with st.spinner(f"åœ¨ Google Places ä¸­æœç´¢ï¼š{query}"):
        places = google_places_search(google_api_key, query)

    if not places:
        st.error("Google Places æœªæ‰¾åˆ°åŒ¹é…é¤å…ï¼Œè¯·æ£€æŸ¥åç§°å’ŒåŸå¸‚ã€‚")
        st.stop()

    # å…ˆç”¨æœç´¢ç»“æœä¸­ç¬¬ä¸€ä¸ª
    target = places[0]
    place_id = target["place_id"]

    with st.spinner("è·å–é¤å…è¯¦æƒ…ï¼ˆGoogle Place Detailsï¼‰..."):
        place_detail = google_place_details(google_api_key, place_id)

    st.success(f"å·²æ‰¾åˆ°é¤å…ï¼š**{place_detail.get('name', 'Unknown')}**")

    # ---------------------------
    # æ˜¾ç¤ºåŸºç¡€ä¿¡æ¯
    # ---------------------------
    st.markdown("### ğŸ§¾ åŸºæœ¬ä¿¡æ¯ï¼ˆæ¥è‡ª Google Placesï¼‰")
    info_cols = st.columns(3)
    with info_cols[0]:
        st.write("**åç§°**:", place_detail.get("name"))
        st.write("**åœ°å€**:", place_detail.get("formatted_address"))
    with info_cols[1]:
        st.write("**ç”µè¯**:", place_detail.get("formatted_phone_number", "N/A"))
        st.write("**è¯„åˆ†**:", place_detail.get("rating", "N/A"))
        st.write("**è¯„è®ºæ•°**:", place_detail.get("user_ratings_total", "N/A"))
    with info_cols[2]:
        st.write("**ä»·æ ¼ç­‰çº§**:", place_detail.get("price_level", "N/A"))
        st.write("**å®˜ç½‘ï¼ˆæ¥è‡ª Googleï¼‰**:", place_detail.get("website", "N/A"))

    geometry = place_detail.get("geometry", {}).get("location", {})
    lat = geometry.get("lat")
    lng = geometry.get("lng")

    # ---------------------------
    # ç«äº‰å¯¹æ‰‹æœç´¢
    # ---------------------------
    st.markdown("## 2ï¸âƒ£ é™„è¿‘ç«äº‰å¯¹æ‰‹ï¼ˆGoogle Places Nearbyï¼‰")

    if lat is None or lng is None:
        st.warning("æœªèƒ½ä» Google è·å–ç»çº¬åº¦ï¼Œæ— æ³•æœç´¢é™„è¿‘ç«äº‰å¯¹æ‰‹ã€‚")
        competitors = []
    else:
        radius_m = int(default_radius_km * 1000)
        with st.spinner("æœç´¢é™„è¿‘é¤å…ä½œä¸ºç«äº‰å¯¹æ‰‹..."):
            competitors = google_places_nearby(
                google_api_key, lat, lng, radius_m, type_="restaurant"
            )

    if competitors:
        comp_data = []
        for c in competitors:
            comp_data.append(
                {
                    "Name": c.get("name"),
                    "Address": c.get("vicinity"),
                    "Rating": c.get("rating", None),
                    "Reviews": c.get("user_ratings_total", 0),
                }
            )
        df_comp = pd.DataFrame(comp_data)
        # æ’é™¤è‡ªå·±
        df_comp = df_comp[
            df_comp["Name"].str.lower()
            != place_detail.get("name", "").lower()
        ]
        df_comp_sorted = df_comp.sort_values(
            by=["Rating", "Reviews"], ascending=[False, False]
        ).reset_index(drop=True)
        st.dataframe(df_comp_sorted, use_container_width=True)
    else:
        st.info("æœªæ‰¾åˆ°ç«äº‰å¯¹æ‰‹ï¼ˆå¯èƒ½åŠå¾„å¤ªå°æˆ– API é™åˆ¶ï¼‰ã€‚")

    # ---------------------------
    # Google å•†å®¶èµ„æ–™è¯„åˆ†
    # ---------------------------
    st.markdown("## 3ï¸âƒ£ Google å•†å®¶èµ„æ–™è¯„åˆ†ï¼ˆ40 åˆ†åˆ¶ï¼‰")

    gbp_result = score_gbp_profile(place_detail)
    st.metric("Google å•†å®¶èµ„æ–™å¾—åˆ†", f"{gbp_result['score']} / 40")

    gbp_rows = []
    for label, (pts, ok) in gbp_result["checks"].items():
        gbp_rows.append(
            {
                "æ£€æŸ¥é¡¹": label,
                "å¾—åˆ†": pts,
                "çŠ¶æ€": "âœ… å®Œæˆ" if ok else "âŒ ç¼ºå¤±/ä¸å®Œæ•´",
            }
        )
    df_gbp = pd.DataFrame(gbp_rows)
    st.table(df_gbp)

    # ---------------------------
    # ç½‘ç«™è¯„åˆ†
    # ---------------------------
    st.markdown("## 4ï¸âƒ£ ç½‘ç«™å†…å®¹ & ä½“éªŒè¯„åˆ†ï¼ˆ40 åˆ†åˆ¶ï¼‰")

    # ä¼˜å…ˆç”¨ Google è¿”å›çš„ç½‘ç«™ï¼Œå¦‚æœç”¨æˆ·æ²¡å¡«æˆ–ä¸ä¸€è‡´ï¼Œå¯ä»¥è‡ªå·±æ”¹
    effective_website = website_url or place_detail.get("website")

    if not effective_website:
        st.warning("æœªæä¾›ç½‘ç«™ URLï¼Œä¹Ÿæ— æ³•ä» Google è·å–ï¼Œç½‘ç«™è¯„åˆ†ä¸º 0ã€‚")
        web_result = {"score": 0, "checks": {"æ— ç½‘ç«™": (0, False)}}
    else:
        with st.spinner(f"æŠ“å–ç½‘ç«™ï¼š{effective_website}"):
            html = fetch_html(effective_website)

        web_result = score_website_basic(effective_website, html)

    st.metric("ç½‘ç«™å¾—åˆ†", f"{web_result['score']} / 40")
    web_rows = []
    for label, (pts, ok) in web_result["checks"].items():
        web_rows.append(
            {
                "æ£€æŸ¥é¡¹": label,
                "å¾—åˆ†": pts,
                "çŠ¶æ€": "âœ… æ˜¯" if ok else "âŒ å¦",
            }
        )
    df_web = pd.DataFrame(web_rows)
    st.table(df_web)

    # ---------------------------
    # æœ¬åœ°å…³é”®è¯æ’åæ¨¡æ‹Ÿ + è¥æ”¶æŸå¤±ä¼°ç®—
    # ---------------------------
    st.markdown("## 5ï¸âƒ£ æœ¬åœ°å…³é”®è¯æ’å & æ½œåœ¨è¥æ”¶æŸå¤±")

    keywords = [k.strip() for k in keywords_input.split(",") if k.strip()]
    rank_results = []

    if not keywords:
        st.info("æœªæä¾›å…³é”®è¯ï¼Œè·³è¿‡æ’åæ¨¡æ‹Ÿå’Œè¥æ”¶ä¼°ç®—ã€‚")
    else:
        for kw in keywords:
            st.write(f"### å…³é”®è¯ï¼š**{kw}**")
            # rank_bucket: top3 / 4-10 / none
            rank_bucket = "none"
            rank_position = None

            if serpapi_key and lat is not None and lng is not None:
                with st.spinner(f"ä½¿ç”¨ SerpAPI æŸ¥è¯¢ Google Maps æ’åï¼š{kw}"):
                    try:
                        serp_json = serpapi_google_maps_search(
                            serpapi_key, kw, lat, lng
                        )
                        rank_position = infer_rank_from_serpapi(
                            serp_json, place_detail.get("name", "")
                        )
                        if rank_position is not None:
                            if rank_position <= 3:
                                rank_bucket = "top3"
                            elif rank_position <= 10:
                                rank_bucket = "4-10"
                            else:
                                rank_bucket = "none"
                    except Exception as e:
                        st.warning(f"SerpAPI æŸ¥è¯¢å‡ºé”™ï¼š{e}")
                        rank_bucket = "none"
                        rank_position = None
            else:
                # æ²¡æœ‰ SerpAPIï¼Œå°±æä¾›ä¸€ä¸ªéå¸¸ç²—ç³™çš„â€œæ¨¡æ‹Ÿâ€ï¼š
                # - å¦‚æœä½ çš„è¯„åˆ†å’Œè¯„è®ºæ•°åœ¨é™„è¿‘ç«äº‰å¯¹æ‰‹ä¸­å±äºå‰åˆ—ï¼Œå°±å‡è®¾è¿›å…¥ 4-10 æˆ– top3ã€‚
                if competitors:
                    all_places = competitors + [place_detail]
                    all_places_data = []
                    for p in all_places:
                        all_places_data.append(
                            {
                                "name": p.get("name", ""),
                                "rating": p.get("rating", 0),
                                "reviews": p.get("user_ratings_total", 0),
                            }
                        )
                    df_all = pd.DataFrame(all_places_data)
                    df_all["score"] = (
                        df_all["rating"].fillna(0) * 10
                        + df_all["reviews"].fillna(0) / 10
                    )
                    df_all = df_all.sort_values(
                        by="score", ascending=False
                    ).reset_index(drop=True)
                    positions = (
                        df_all["name"]
                        .str.lower()
                        .tolist()
                    )
                    if place_detail.get("name", "").lower() in positions:
                        pos = positions.index(
                            place_detail.get("name", "").lower()
                        ) + 1
                        rank_position = pos
                        if pos <= 3:
                            rank_bucket = "top3"
                        elif pos <= 10:
                            rank_bucket = "4-10"
                        else:
                            rank_bucket = "none"
                    else:
                        rank_bucket = "none"

            # è®¡ç®—è¥æ”¶æŸå¤±
            monthly_loss = estimate_revenue_loss(
                monthly_search_volume,
                rank_bucket,
                avg_order_value,
                assumed_ctr,
                assumed_conv,
            )

            st.write(
                f"- ä¼°è®¡å½“å‰æ’åï¼š"
                f"{'Top 3' if rank_bucket=='top3' else ('ç¬¬ 4â€“10 å' if rank_bucket=='4-10' else 'æœªè¿›å…¥å‰ 10')}"
                f"{'' if rank_position is None else f'ï¼ˆæ¨æµ‹åæ¬¡ï¼š{rank_position}ï¼‰'}"
            )
            st.write(
                f"- ç²—ç•¥ä¼°è®¡ï¼šç”±äºæ²¡æœ‰åœ¨ç†æƒ³ä½ç½®ï¼Œ**æ¯æœˆå¯èƒ½å°‘èµšçº¦ ${monthly_loss:,.0f}**"
            )

            rank_results.append(
                {
                    "å…³é”®è¯": kw,
                    "é¢„ä¼°åæ¬¡": rank_position,
                    "åæ¬¡åŒºé—´": rank_bucket,
                    "é¢„ä¼°æœˆæŸå¤±($)": round(monthly_loss, 2),
                }
            )

        if rank_results:
            st.markdown("#### å…³é”®è¯ & è¥æ”¶æŸå¤±æ±‡æ€»")
            df_rank = pd.DataFrame(rank_results)
            st.dataframe(df_rank, use_container_width=True)

    # ---------------------------
    # æ€»ç»“
    # ---------------------------
    st.markdown("## 6ï¸âƒ£ æ€»ä½“åœ¨çº¿å¥åº·æ€»ç»“")

    total_score = gbp_result["score"] + web_result["score"]
    st.metric("ç»¼åˆå¾—åˆ†ï¼ˆProfile + Websiteï¼‰", f"{total_score} / 80")

    st.write(
        "- **40 åˆ†ä»¥ä¸‹**ï¼šåœ¨çº¿åŸºç¡€éå¸¸å¼±ï¼ŒåŸºæœ¬å±äº â€œPoorâ€ çŠ¶æ€ã€‚\n"
        "- **40â€“60 åˆ†**ï¼šä¸­ç­‰ï¼Œèƒ½è¢«æ‰¾åˆ°ï¼Œä½†æ²¡æœ‰ä¼˜åŠ¿ã€‚\n"
        "- **60 åˆ†ä»¥ä¸Š**ï¼šç›¸å¯¹å¥åº·ï¼Œä½†ä»æœ‰ä¼˜åŒ–ç©ºé—´ï¼Œç‰¹åˆ«æ˜¯å…³é”®è¯å¸ƒå±€å’Œæ´»åŠ¨æ¨å¹¿ã€‚\n"
    )

    st.info(
        "å»ºè®®ä¸‹ä¸€æ­¥ï¼š\n"
        "1. æŠŠä¸Šé¢çš„è¡¨æ ¼å¯¼å‡ºç»™è€æ¿ï¼ˆæˆ–ä½ è‡ªå·±çš„å®¢æˆ·ï¼‰ï¼Œé€é¡¹å‹¾é€‰ä¼˜åŒ–ã€‚\n"
        "2. åç»­å¯ä»¥æ¥å…¥ï¼šGoogle Business Profile API èœå•ã€Yelp APIã€DoorDash/UberEats èœå•æŠ“å–ã€"
        "ä»¥åŠå…³é”®è¯çœŸå®æœç´¢é‡ APIï¼Œåšæˆæ›´æ¥è¿‘ Owner.com çš„å®Œæ•´ç³»ç»Ÿã€‚"
    )

# ========== ç½²åï¼ˆLinkedInï¼‰ ==========
LINKEDIN_URL = "https://www.linkedin.com/in/lingyu-maxwell-lai"
st.markdown(
    f"""
<div style="display:flex;align-items:center;gap:10px;margin-top:-6px;margin-bottom:8px;">
  <div style="font-size:14px;color:#666;">
    Builded by <strong>Maxwell Lai</strong>
  </div>
  <a href="{LINKEDIN_URL}" target="_blank" title="LinkedIn: Maxwell Lai"
     style="display:inline-flex;align-items:center;justify-content:center;width:18px;height:18px;
            border-radius:4px;background:#0A66C2;">
    <img src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons/icons/linkedin.svg"
         alt="LinkedIn" width="12" height="12" style="filter: invert(1);" />
  </a>
</div>
""",
    unsafe_allow_html=True,
)
